{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyro-ppl in /home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages (1.8.1)\n",
      "Collecting torch>=1.11.0\n",
      "  Using cached torch-1.11.0-cp37-cp37m-manylinux1_x86_64.whl (750.6 MB)\n",
      "Requirement already satisfied: tqdm>=4.36 in /home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages (from pyro-ppl) (4.62.1)\n",
      "Requirement already satisfied: pyro-api>=0.1.1 in /home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages (from pyro-ppl) (0.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages (from pyro-ppl) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages (from pyro-ppl) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions in /home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages (from torch>=1.11.0->pyro-ppl) (3.10.0.0)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.10.2+cu113\n",
      "    Uninstalling torch-1.10.2+cu113:\n",
      "      Successfully uninstalled torch-1.10.2+cu113\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 0.9.0 requires torch==1.9.0, but you have torch 1.11.0 which is incompatible.\u001b[0m\n",
      "Successfully installed torch-1.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyro-ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples in data:  3549\n",
      "Data shape for state: (3549, 11), action: (3549, 1), parameter: (3549, 5), next_state:(3549, 11)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = os.path.abspath(os.path.join(os.getcwd(),\"..\"))\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from dynamics_predict.defaults import DYNAMICS_PARAMS, HYPER_PARAMS\n",
    "\n",
    "def load_data(env_name):\n",
    "    data_path = '../data/dynamics_data/'+env_name+'/dynamics.npy'\n",
    "    train_data = np.load(data_path, allow_pickle=True)\n",
    "    print('number of samples in data: ', len(train_data))\n",
    "    # split data\n",
    "    data_s, data_a, data_param, data_s_ = [], [], [], []\n",
    "    for d in train_data:\n",
    "        [s,a,param], s_ = d\n",
    "        data_s.append(s)\n",
    "        data_a.append(a)\n",
    "        data_param.append(param)\n",
    "        data_s_.append(s_)\n",
    "\n",
    "    data_s = np.array(data_s)\n",
    "    data_a = np.array(data_a)\n",
    "    data_param = np.array(data_param)\n",
    "    data_s_ = np.array(data_s_)\n",
    "\n",
    "    print(f'Data shape for state: {data_s.shape}, action: {data_a.shape}, parameter: {data_param.shape}, next_state:{data_s_.shape}')\n",
    "\n",
    "    return data_s, data_a, data_param, data_s_\n",
    "\n",
    "env_name = 'inverteddoublependulum'\n",
    "data_s, data_a, data_param, data_s_ = load_data(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3549, 12) (3549, 11)\n"
     ]
    }
   ],
   "source": [
    "x = np.concatenate((data_s,data_a), axis=-1)\n",
    "theta = data_param\n",
    "y = data_s_\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "s_dim = data_s.shape[-1]\n",
    "a_dim = data_a.shape[-1]\n",
    "param_dim = data_param.shape[-1]\n",
    "latent_dim = 3\n",
    "print('parameter dimension: ', param_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "class DynamicsEncoder(nn.Module):\n",
    "    \"\"\" Dynamics parameters encoding network: (params) -> (latent code) \"\"\"\n",
    "    def __init__(self, param_dim, latent_dim, hidden_dim=32, hidden_activation=F.relu, output_activation=F.tanh, num_hidden_layers=2, lr=1e-3, gamma=0.99):\n",
    "        super(DynamicsEncoder, self).__init__()\n",
    "        \n",
    "        self.hidden_activation = hidden_activation\n",
    "        self.output_activation = output_activation\n",
    "        self._param_dim = param_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "\n",
    "        self.input_layer =  nn.Linear(self._param_dim, hidden_dim)\n",
    "        self.hidden_layers = [nn.Linear(hidden_dim, hidden_dim) for _ in range(num_hidden_layers)]\n",
    "        self.hidden_layers = nn.ModuleList(self.hidden_layers)  # Have to wrap the list layers with nn.ModuleList to coorectly make those parameters tracked by nn.module! Otherwise those params will not be saved!\n",
    "        self.output_layer =  nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        # self.scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.99)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.Tensor(x)\n",
    "        x=self.hidden_activation(self.input_layer(x))\n",
    "        for hl in self.hidden_layers:\n",
    "            x=self.hidden_activation(hl(x))\n",
    "        x=self.output_layer(x)\n",
    "        if self.output_activation is not None:\n",
    "            x=self.output_activation(x)\n",
    "        return x\n",
    "\n",
    "## a standard NN\n",
    "# class EmbeddingDynamicsNetwork(nn.Module):\n",
    "#     \"\"\" Common class for dyanmics prediction network with dynamics embedding as input: (s,a, alpha) -> s' \"\"\"\n",
    "#     def __init__(self, s_dim, a_dim, latent_dim, hidden_dim=32, hidden_activation=F.relu, output_activation=F.tanh, num_hidden_layers=2, lr=1e-3, gamma=0.99):\n",
    "#         super(EmbeddingDynamicsNetwork, self).__init__()\n",
    "        \n",
    "#         self.hidden_activation = hidden_activation\n",
    "#         self.output_activation = output_activation\n",
    "#         self.latent_dim = latent_dim\n",
    "#         self.num_hidden_layers = num_hidden_layers\n",
    "\n",
    "#         self.input_layer =  nn.Linear(s_dim+a_dim+self.latent_dim, hidden_dim)\n",
    "#         self.hidden_layers = [nn.Linear(hidden_dim, hidden_dim) for _ in range(num_hidden_layers)]\n",
    "#         self.hidden_layers = nn.ModuleList(self.hidden_layers)  # Have to wrap the list layers with nn.ModuleList to coorectly make those parameters tracked by nn.module! Otherwise those params will not be saved!\n",
    "#         self.output_layer =  nn.Linear(hidden_dim, s_dim)\n",
    "\n",
    "#         self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "#         # self.scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.99)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         if not isinstance(x, torch.Tensor):\n",
    "#             x = torch.Tensor(x)\n",
    "#         x=self.hidden_activation(self.input_layer(x))\n",
    "#         for hl in self.hidden_layers:\n",
    "#             x=self.hidden_activation(hl(x))\n",
    "#         x=self.output_layer(x)\n",
    "#         if self.output_activation is not None:\n",
    "#             x=self.output_activation(x)\n",
    "#         return x\n",
    "\n",
    "## a handwritten NN\n",
    "class EmbeddingDynamicsNetwork(nn.Module):\n",
    "    \"\"\" Common class for dyanmics prediction network with dynamics embedding as input: (s,a, alpha) -> s' \"\"\"\n",
    "    def __init__(self, s_dim, a_dim, latent_dim, hidden_dim=32, hidden_activation=F.relu, output_activation=F.tanh, num_hidden_layers=2, lr=1e-3, gamma=0.99):\n",
    "        super(EmbeddingDynamicsNetwork, self).__init__()\n",
    "        \n",
    "        in_size = s_dim+a_dim+latent_dim\n",
    "        out_size = s_dim\n",
    "\n",
    "        self.weights1 =  nn.Parameter(torch.randn(in_size, hidden_dim))\n",
    "        self.bias1 = nn.Parameter(torch.randn(hidden_dim))\n",
    "        self.weights2 =  nn.Parameter(torch.randn(hidden_dim, out_size))\n",
    "        self.bias2 = nn.Parameter(torch.randn(out_size))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        # self.scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.99)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.Tensor(x)\n",
    "        x = self.relu(x @ self.weights1 + self.bias1)\n",
    "        y = x @ self.weights2 + self.bias2\n",
    "        return y\n",
    "\n",
    "## just a linear layer\n",
    "# class EmbeddingDynamicsNetwork(nn.Module):\n",
    "#     \"\"\" Common class for dyanmics prediction network with dynamics embedding as input: (s,a, alpha) -> s' \"\"\"\n",
    "#     def __init__(self, s_dim, a_dim, latent_dim, hidden_dim=32, hidden_activation=F.relu, output_activation=F.tanh, num_hidden_layers=2, lr=1e-3, gamma=0.99):\n",
    "#         super(EmbeddingDynamicsNetwork, self).__init__()\n",
    "        \n",
    "#         in_size = s_dim+a_dim+latent_dim\n",
    "#         out_size = s_dim\n",
    "\n",
    "#         self.weights =  nn.Parameter(torch.randn(in_size, out_size))\n",
    "#         self.bias = nn.Parameter(torch.randn(out_size))\n",
    "\n",
    "#         self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "#         # self.scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.99)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         if not isinstance(x, torch.Tensor):\n",
    "#             x = torch.Tensor(x)\n",
    "#         y = x @ self.weights + self.bias\n",
    "#         return y\n",
    "\n",
    "class DynamicsParamsOptimizer():\n",
    "    \"\"\" \n",
    "    Dynamics parameters optimization model (gradient-based) based on a trained \n",
    "    forward dynamics prediction network: (s, a, learnable_params) -> s_ with real-world data. \n",
    "    \"\"\"\n",
    "    def __init__(self, s_dim, a_dim, param_dim, latent_dim, hidden_dim=32, hidden_activation=F.relu, output_activation=None, num_hidden_layers=4, lr=1e-2, gamma=0.99):\n",
    "        self.dynamics_model = EmbeddingDynamicsNetwork(s_dim, a_dim, latent_dim, hidden_dim, hidden_activation, output_activation, num_hidden_layers, lr, gamma).to(device)\n",
    "        self.dynamics_encoder = DynamicsEncoder(param_dim, latent_dim, hidden_dim, hidden_activation, output_activation, num_hidden_layers, lr, gamma).to(device)\n",
    "        self.optimizer = torch.optim.Adam(list(self.dynamics_model.parameters()) + list(self.dynamics_encoder.parameters()), lr=lr)\n",
    "\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x, theta):\n",
    "        \"\"\" s,a concat with param (learnable) -> s_ \"\"\"\n",
    "\n",
    "        alpha = self.dynamics_encoder(theta)\n",
    "        y_  = self.dynamics_model(torch.cat((x, alpha), axis=-1))\n",
    "        \n",
    "        return y_\n",
    "\n",
    "    def update(self, data, epoch=200, model_save_path=None):\n",
    "        (x, theta, y) = data\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.Tensor(x).to(device)\n",
    "        if not isinstance(theta, torch.Tensor):\n",
    "            theta = torch.Tensor(theta).to(device)        \n",
    "        if not isinstance(y, torch.Tensor):\n",
    "            y = torch.Tensor(y).to(device)\n",
    "\n",
    "        for ep in range(epoch):\n",
    "            y_ = self.forward(x, theta)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.loss(y_, y)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if ep%100==0:\n",
    "                print('epoch: {}, loss: {}'.format(ep, loss.item()))\n",
    "                torch.save(self.dynamics_model.state_dict(), model_save_path+'dynamics_model')\n",
    "                torch.save(self.dynamics_encoder.state_dict(), model_save_path+'dynamics_encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 104.70088958740234\n",
      "epoch: 100, loss: 1.5119788646697998\n",
      "epoch: 200, loss: 0.7165051102638245\n",
      "epoch: 300, loss: 0.474081814289093\n",
      "epoch: 400, loss: 0.36683470010757446\n",
      "epoch: 500, loss: 0.30265212059020996\n",
      "epoch: 600, loss: 0.25668197870254517\n",
      "epoch: 700, loss: 0.22272521257400513\n",
      "epoch: 800, loss: 0.20104274153709412\n",
      "epoch: 900, loss: 0.18649204075336456\n",
      "epoch: 1000, loss: 0.17585842311382294\n",
      "epoch: 1100, loss: 0.16783331334590912\n",
      "epoch: 1200, loss: 0.16123859584331512\n",
      "epoch: 1300, loss: 0.15561211109161377\n",
      "epoch: 1400, loss: 0.1508135348558426\n",
      "epoch: 1500, loss: 0.146688774228096\n",
      "epoch: 1600, loss: 0.1422354131937027\n",
      "epoch: 1700, loss: 0.1396695226430893\n",
      "epoch: 1800, loss: 0.13450342416763306\n",
      "epoch: 1900, loss: 0.1340285688638687\n",
      "epoch: 2000, loss: 0.1280069649219513\n",
      "epoch: 2100, loss: 0.12448101490736008\n",
      "epoch: 2200, loss: 0.11847130954265594\n",
      "epoch: 2300, loss: 0.114168182015419\n",
      "epoch: 2400, loss: 0.11029716581106186\n",
      "epoch: 2500, loss: 0.10651625692844391\n",
      "epoch: 2600, loss: 0.1036386638879776\n",
      "epoch: 2700, loss: 0.10891847312450409\n",
      "epoch: 2800, loss: 0.09725842624902725\n",
      "epoch: 2900, loss: 0.0945204421877861\n",
      "epoch: 3000, loss: 0.09212688356637955\n",
      "epoch: 3100, loss: 0.09093230217695236\n",
      "epoch: 3200, loss: 0.08771147578954697\n",
      "epoch: 3300, loss: 0.08606835454702377\n",
      "epoch: 3400, loss: 0.08454851061105728\n",
      "epoch: 3500, loss: 0.08334218710660934\n",
      "epoch: 3600, loss: 0.0822523832321167\n",
      "epoch: 3700, loss: 0.080777108669281\n",
      "epoch: 3800, loss: 0.07879112660884857\n",
      "epoch: 3900, loss: 0.07723979651927948\n",
      "epoch: 4000, loss: 0.07520047575235367\n",
      "epoch: 4100, loss: 0.07357803732156754\n",
      "epoch: 4200, loss: 0.07251038402318954\n",
      "epoch: 4300, loss: 0.06887916475534439\n",
      "epoch: 4400, loss: 0.06615683436393738\n",
      "epoch: 4500, loss: 0.06452684849500656\n",
      "epoch: 4600, loss: 0.060640718787908554\n",
      "epoch: 4700, loss: 0.05946487560868263\n",
      "epoch: 4800, loss: 0.05675119161605835\n",
      "epoch: 4900, loss: 0.05519698187708855\n",
      "epoch: 5000, loss: 0.05281083285808563\n",
      "epoch: 5100, loss: 0.05821647867560387\n",
      "epoch: 5200, loss: 0.04879142716526985\n",
      "epoch: 5300, loss: 0.047871436923742294\n",
      "epoch: 5400, loss: 0.0462111197412014\n",
      "epoch: 5500, loss: 0.04430482164025307\n",
      "epoch: 5600, loss: 0.04349836707115173\n",
      "epoch: 5700, loss: 0.04350779950618744\n",
      "epoch: 5800, loss: 0.04102572426199913\n",
      "epoch: 5900, loss: 0.04024449363350868\n",
      "epoch: 6000, loss: 0.039453260600566864\n",
      "epoch: 6100, loss: 0.03888574242591858\n",
      "epoch: 6200, loss: 0.0373915433883667\n",
      "epoch: 6300, loss: 0.038049738854169846\n",
      "epoch: 6400, loss: 0.03668006509542465\n",
      "epoch: 6500, loss: 0.04549407586455345\n",
      "epoch: 6600, loss: 0.03541043400764465\n",
      "epoch: 6700, loss: 0.03523377329111099\n",
      "epoch: 6800, loss: 0.03455723822116852\n",
      "epoch: 6900, loss: 0.03449815884232521\n",
      "epoch: 7000, loss: 0.03354549780488014\n",
      "epoch: 7100, loss: 0.03294096887111664\n",
      "epoch: 7200, loss: 0.03228951245546341\n",
      "epoch: 7300, loss: 0.0317828431725502\n",
      "epoch: 7400, loss: 0.03209613263607025\n",
      "epoch: 7500, loss: 0.03114115260541439\n",
      "epoch: 7600, loss: 0.03420042619109154\n",
      "epoch: 7700, loss: 0.030962752178311348\n",
      "epoch: 7800, loss: 0.029981380328536034\n",
      "epoch: 7900, loss: 0.029609043151140213\n",
      "epoch: 8000, loss: 0.029426181688904762\n",
      "epoch: 8100, loss: 0.03226868808269501\n",
      "epoch: 8200, loss: 0.029699567705392838\n",
      "epoch: 8300, loss: 0.02884185127913952\n",
      "epoch: 8400, loss: 0.028452200815081596\n",
      "epoch: 8500, loss: 0.027902010828256607\n",
      "epoch: 8600, loss: 0.028425415977835655\n",
      "epoch: 8700, loss: 0.02849828451871872\n",
      "epoch: 8800, loss: 0.027458712458610535\n",
      "epoch: 8900, loss: 0.029486797749996185\n",
      "epoch: 9000, loss: 0.026742326095700264\n",
      "epoch: 9100, loss: 0.02683340571820736\n",
      "epoch: 9200, loss: 0.028936058282852173\n",
      "epoch: 9300, loss: 0.027819830924272537\n",
      "epoch: 9400, loss: 0.026310995221138\n",
      "epoch: 9500, loss: 0.027021706104278564\n",
      "epoch: 9600, loss: 0.026707379147410393\n",
      "epoch: 9700, loss: 0.03456607833504677\n",
      "epoch: 9800, loss: 0.025658385828137398\n",
      "epoch: 9900, loss: 0.02556139975786209\n",
      "epoch: 10000, loss: 0.025758543983101845\n",
      "epoch: 10100, loss: 0.025776715949177742\n",
      "epoch: 10200, loss: 0.02578793279826641\n",
      "epoch: 10300, loss: 0.025299083441495895\n",
      "epoch: 10400, loss: 0.02615278586745262\n",
      "epoch: 10500, loss: 0.024961011484265327\n",
      "epoch: 10600, loss: 0.02475561387836933\n",
      "epoch: 10700, loss: 0.02494683675467968\n",
      "epoch: 10800, loss: 0.02457897737622261\n",
      "epoch: 10900, loss: 0.027473196387290955\n",
      "epoch: 11000, loss: 0.024720046669244766\n",
      "epoch: 11100, loss: 0.024683913215994835\n",
      "epoch: 11200, loss: 0.024151327088475227\n",
      "epoch: 11300, loss: 0.025498278439044952\n",
      "epoch: 11400, loss: 0.024726757779717445\n",
      "epoch: 11500, loss: 0.024188023060560226\n",
      "epoch: 11600, loss: 0.02381567843258381\n",
      "epoch: 11700, loss: 0.02635517716407776\n",
      "epoch: 11800, loss: 0.023884935304522514\n",
      "epoch: 11900, loss: 0.02343280240893364\n",
      "epoch: 12000, loss: 0.02333897165954113\n",
      "epoch: 12100, loss: 0.02356850914657116\n",
      "epoch: 12200, loss: 0.024297146126627922\n",
      "epoch: 12300, loss: 0.02411709912121296\n",
      "epoch: 12400, loss: 0.023566659539937973\n",
      "epoch: 12500, loss: 0.023943373933434486\n",
      "epoch: 12600, loss: 0.02365087904036045\n",
      "epoch: 12700, loss: 0.023116813972592354\n",
      "epoch: 12800, loss: 0.02931661158800125\n",
      "epoch: 12900, loss: 0.02316666767001152\n",
      "epoch: 13000, loss: 0.028143612667918205\n",
      "epoch: 13100, loss: 0.022735362872481346\n",
      "epoch: 13200, loss: 0.023166105151176453\n",
      "epoch: 13300, loss: 0.02577430009841919\n",
      "epoch: 13400, loss: 0.022712841629981995\n",
      "epoch: 13500, loss: 0.02759685181081295\n",
      "epoch: 13600, loss: 0.025210341438651085\n",
      "epoch: 13700, loss: 0.023501791059970856\n",
      "epoch: 13800, loss: 0.022648800164461136\n",
      "epoch: 13900, loss: 0.022586772218346596\n",
      "epoch: 14000, loss: 0.02246558479964733\n",
      "epoch: 14100, loss: 0.022061098366975784\n",
      "epoch: 14200, loss: 0.02342996373772621\n",
      "epoch: 14300, loss: 0.022086624056100845\n",
      "epoch: 14400, loss: 0.022339120507240295\n",
      "epoch: 14500, loss: 0.02258160337805748\n",
      "epoch: 14600, loss: 0.02360611781477928\n",
      "epoch: 14700, loss: 0.022712254896759987\n",
      "epoch: 14800, loss: 0.02203242853283882\n",
      "epoch: 14900, loss: 0.027407651767134666\n",
      "epoch: 15000, loss: 0.02315550111234188\n",
      "epoch: 15100, loss: 0.022114155814051628\n",
      "epoch: 15200, loss: 0.02171037718653679\n",
      "epoch: 15300, loss: 0.024395691230893135\n",
      "epoch: 15400, loss: 0.02446543239057064\n",
      "epoch: 15500, loss: 0.021634049713611603\n",
      "epoch: 15600, loss: 0.022711260244250298\n",
      "epoch: 15700, loss: 0.022261446341872215\n",
      "epoch: 15800, loss: 0.022593604400753975\n",
      "epoch: 15900, loss: 0.0217354167252779\n",
      "epoch: 16000, loss: 0.02240568771958351\n",
      "epoch: 16100, loss: 0.02185853198170662\n",
      "epoch: 16200, loss: 0.022070331498980522\n",
      "epoch: 16300, loss: 0.022098509594798088\n",
      "epoch: 16400, loss: 0.0218143742531538\n",
      "epoch: 16500, loss: 0.022275278344750404\n",
      "epoch: 16600, loss: 0.021576764062047005\n",
      "epoch: 16700, loss: 0.021226322278380394\n",
      "epoch: 16800, loss: 0.021221483126282692\n",
      "epoch: 16900, loss: 0.021590420976281166\n",
      "epoch: 17000, loss: 0.022865764796733856\n",
      "epoch: 17100, loss: 0.021957578137516975\n",
      "epoch: 17200, loss: 0.021732574328780174\n",
      "epoch: 17300, loss: 0.02131594531238079\n",
      "epoch: 17400, loss: 0.021315567195415497\n",
      "epoch: 17500, loss: 0.022732185199856758\n",
      "epoch: 17600, loss: 0.021355077624320984\n",
      "epoch: 17700, loss: 0.021380294114351273\n",
      "epoch: 17800, loss: 0.021482795476913452\n",
      "epoch: 17900, loss: 0.02143133617937565\n",
      "epoch: 18000, loss: 0.02265656180679798\n",
      "epoch: 18100, loss: 0.021156299859285355\n",
      "epoch: 18200, loss: 0.021258819848299026\n",
      "epoch: 18300, loss: 0.02556316927075386\n",
      "epoch: 18400, loss: 0.023602748289704323\n",
      "epoch: 18500, loss: 0.021474331617355347\n",
      "epoch: 18600, loss: 0.022300126031041145\n",
      "epoch: 18700, loss: 0.020789697766304016\n",
      "epoch: 18800, loss: 0.03477681055665016\n",
      "epoch: 18900, loss: 0.021250177174806595\n",
      "epoch: 19000, loss: 0.021070702001452446\n",
      "epoch: 19100, loss: 0.020984604954719543\n",
      "epoch: 19200, loss: 0.0210066307336092\n",
      "epoch: 19300, loss: 0.0254986472427845\n",
      "epoch: 19400, loss: 0.021994488313794136\n",
      "epoch: 19500, loss: 0.02161608263850212\n",
      "epoch: 19600, loss: 0.023875044658780098\n",
      "epoch: 19700, loss: 0.022162923589348793\n",
      "epoch: 19800, loss: 0.02106701210141182\n",
      "epoch: 19900, loss: 0.021803000941872597\n"
     ]
    }
   ],
   "source": [
    "#stage 1, learning forward dynamics and dynamics encoder\n",
    "opt = DynamicsParamsOptimizer(s_dim, a_dim, param_dim, latent_dim)\n",
    "data = (x, theta, y)\n",
    "model_save_path = './model/test/'\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "opt.update(data, epoch=20000, model_save_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stage 2, using BNN and SVI to fit alpha\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.nn import PyroModule, PyroSample\n",
    "import torch.nn as nn\n",
    "from pyro.infer.autoguide import AutoNormal, AutoDiagonalNormal\n",
    "from pyro.infer import SVI, Trace_ELBO, Predictive\n",
    "from tqdm.auto import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples in dest data:  10\n",
      "(4401, 11) (4401, 1) (5,) (4401, 11)\n"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "test_data_path = path+'/data/dynamics_data/'+env_name+'/test_dynamics.npy'\n",
    "test_data = np.load(test_data_path, allow_pickle=True)\n",
    "print('number of samples in dest data: ', len(test_data))\n",
    "idx=8  # index of sample to test: 0-10\n",
    "test_s = np.array(test_data[idx]['sa'])[:, :-1]\n",
    "test_a = np.array(test_data[idx]['sa'])[:, -1:]\n",
    "test_param = np.array(test_data[idx]['params'])\n",
    "test_s_ = np.array(test_data[idx]['s_'])\n",
    "print(test_s.shape, test_a.shape, test_param.shape, test_s_.shape)\n",
    "\n",
    "# load model\n",
    "# updater = DynamicsParamsOptimizer(state_dim, action_dim, param_dim, latent_dim, switch_dim, model_save_path)\n",
    "# updater.model.load_state_dict(torch.load(model_save_path+'model', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 12]) torch.Size([1000, 11]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "test_num_samples = 1000\n",
    "test_x = torch.from_numpy(np.concatenate((test_s,test_a), axis=-1)).float()[:test_num_samples]\n",
    "test_y = torch.from_numpy(test_s_).float()[:test_num_samples]\n",
    "test_param = torch.from_numpy(test_param).float()\n",
    "\n",
    "x_dim = test_x.shape[1]\n",
    "y_dim = test_y.shape[1]\n",
    "print(test_x.shape, test_y.shape, test_param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 12]) torch.Size([1000, 11]) torch.float32\n",
      "torch.Size([1000, 12]) torch.Size([1000, 11]) torch.float32\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([0.0419, 0.0319, 0.5833], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0991, 0.0991, 0.0991], grad_fn=<SoftplusBackward0>)\n",
      "step 0 loss = 2.124e+05\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.3489, -0.6290, -0.2157], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0904, 0.0867, 0.1115], grad_fn=<SoftplusBackward0>)\n",
      "step 100 loss = 3.311e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.1828, -0.9505, -0.6497], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0793, 0.0804, 0.1049], grad_fn=<SoftplusBackward0>)\n",
      "step 200 loss = 1.349e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.1242, -1.1648, -0.8767], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0689, 0.0740, 0.0925], grad_fn=<SoftplusBackward0>)\n",
      "step 300 loss = 1.108e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.1720, -1.2595, -0.9719], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0604, 0.0688, 0.0840], grad_fn=<SoftplusBackward0>)\n",
      "step 400 loss = 8308\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2342, -1.2986, -1.0187], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0531, 0.0630, 0.0775], grad_fn=<SoftplusBackward0>)\n",
      "step 500 loss = 6416\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2523, -1.2991, -1.0284], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0498, 0.0581, 0.0712], grad_fn=<SoftplusBackward0>)\n",
      "step 600 loss = 6276\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2678, -1.3046, -1.0402], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0453, 0.0542, 0.0665], grad_fn=<SoftplusBackward0>)\n",
      "step 700 loss = 6499\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2560, -1.3021, -1.0511], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0417, 0.0515, 0.0610], grad_fn=<SoftplusBackward0>)\n",
      "step 800 loss = 6419\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2577, -1.2908, -1.0505], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0394, 0.0482, 0.0562], grad_fn=<SoftplusBackward0>)\n",
      "step 900 loss = 6241\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2645, -1.3082, -1.0481], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0367, 0.0443, 0.0525], grad_fn=<SoftplusBackward0>)\n",
      "step 1000 loss = 6187\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2645, -1.3110, -1.0436], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0337, 0.0415, 0.0492], grad_fn=<SoftplusBackward0>)\n",
      "step 1100 loss = 6132\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2569, -1.3023, -1.0503], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0319, 0.0391, 0.0462], grad_fn=<SoftplusBackward0>)\n",
      "step 1200 loss = 6095\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2814, -1.2965, -1.0381], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0299, 0.0369, 0.0436], grad_fn=<SoftplusBackward0>)\n",
      "step 1300 loss = 6186\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2634, -1.3032, -1.0420], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0278, 0.0351, 0.0409], grad_fn=<SoftplusBackward0>)\n",
      "step 1400 loss = 6344\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2602, -1.3016, -1.0471], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0255, 0.0334, 0.0389], grad_fn=<SoftplusBackward0>)\n",
      "step 1500 loss = 6238\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2578, -1.3034, -1.0462], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0238, 0.0317, 0.0370], grad_fn=<SoftplusBackward0>)\n",
      "step 1600 loss = 6235\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2534, -1.2935, -1.0482], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0226, 0.0302, 0.0351], grad_fn=<SoftplusBackward0>)\n",
      "step 1700 loss = 6399\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2594, -1.3008, -1.0545], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0216, 0.0288, 0.0333], grad_fn=<SoftplusBackward0>)\n",
      "step 1800 loss = 6107\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2534, -1.3064, -1.0373], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0208, 0.0276, 0.0320], grad_fn=<SoftplusBackward0>)\n",
      "step 1900 loss = 6101\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2692, -1.2948, -1.0479], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0196, 0.0262, 0.0306], grad_fn=<SoftplusBackward0>)\n",
      "step 2000 loss = 6167\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2609, -1.3025, -1.0504], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0187, 0.0251, 0.0293], grad_fn=<SoftplusBackward0>)\n",
      "step 2100 loss = 6110\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2581, -1.3022, -1.0523], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0180, 0.0242, 0.0281], grad_fn=<SoftplusBackward0>)\n",
      "step 2200 loss = 6206\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2645, -1.2948, -1.0531], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0171, 0.0232, 0.0268], grad_fn=<SoftplusBackward0>)\n",
      "step 2300 loss = 6272\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2559, -1.2973, -1.0453], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0164, 0.0223, 0.0259], grad_fn=<SoftplusBackward0>)\n",
      "step 2400 loss = 6089\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2514, -1.2934, -1.0461], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0156, 0.0216, 0.0249], grad_fn=<SoftplusBackward0>)\n",
      "step 2500 loss = 6168\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2595, -1.3003, -1.0447], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0151, 0.0208, 0.0238], grad_fn=<SoftplusBackward0>)\n",
      "step 2600 loss = 6138\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2550, -1.2982, -1.0389], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0146, 0.0200, 0.0230], grad_fn=<SoftplusBackward0>)\n",
      "step 2700 loss = 6094\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2606, -1.2933, -1.0477], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0141, 0.0192, 0.0223], grad_fn=<SoftplusBackward0>)\n",
      "step 2800 loss = 6098\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2585, -1.2961, -1.0465], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0137, 0.0185, 0.0214], grad_fn=<SoftplusBackward0>)\n",
      "step 2900 loss = 6078\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2614, -1.2991, -1.0442], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0133, 0.0180, 0.0207], grad_fn=<SoftplusBackward0>)\n",
      "step 3000 loss = 6098\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2563, -1.2902, -1.0453], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0128, 0.0175, 0.0201], grad_fn=<SoftplusBackward0>)\n",
      "step 3100 loss = 6112\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2412, -1.2884, -1.0490], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0123, 0.0168, 0.0194], grad_fn=<SoftplusBackward0>)\n",
      "step 3200 loss = 6090\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2546, -1.3056, -1.0464], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0117, 0.0163, 0.0187], grad_fn=<SoftplusBackward0>)\n",
      "step 3300 loss = 6084\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2545, -1.2975, -1.0566], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0114, 0.0159, 0.0181], grad_fn=<SoftplusBackward0>)\n",
      "step 3400 loss = 6096\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2630, -1.3006, -1.0505], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0110, 0.0155, 0.0175], grad_fn=<SoftplusBackward0>)\n",
      "step 3500 loss = 6085\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2683, -1.2939, -1.0452], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0106, 0.0149, 0.0169], grad_fn=<SoftplusBackward0>)\n",
      "step 3600 loss = 6089\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2576, -1.3002, -1.0466], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0103, 0.0145, 0.0164], grad_fn=<SoftplusBackward0>)\n",
      "step 3700 loss = 6079\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2630, -1.2989, -1.0502], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0099, 0.0140, 0.0159], grad_fn=<SoftplusBackward0>)\n",
      "step 3800 loss = 6091\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2677, -1.2989, -1.0425], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0095, 0.0136, 0.0155], grad_fn=<SoftplusBackward0>)\n",
      "step 3900 loss = 6144\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2510, -1.2993, -1.0470], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0091, 0.0132, 0.0149], grad_fn=<SoftplusBackward0>)\n",
      "step 4000 loss = 6082\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2618, -1.2957, -1.0501], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0088, 0.0128, 0.0145], grad_fn=<SoftplusBackward0>)\n",
      "step 4100 loss = 6079\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2702, -1.3039, -1.0365], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0086, 0.0124, 0.0140], grad_fn=<SoftplusBackward0>)\n",
      "step 4200 loss = 6075\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2604, -1.2963, -1.0471], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0083, 0.0120, 0.0136], grad_fn=<SoftplusBackward0>)\n",
      "step 4300 loss = 6081\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2627, -1.2921, -1.0408], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0081, 0.0116, 0.0132], grad_fn=<SoftplusBackward0>)\n",
      "step 4400 loss = 6082\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2689, -1.2993, -1.0505], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0078, 0.0112, 0.0128], grad_fn=<SoftplusBackward0>)\n",
      "step 4500 loss = 6081\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2643, -1.2962, -1.0403], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0076, 0.0108, 0.0124], grad_fn=<SoftplusBackward0>)\n",
      "step 4600 loss = 6076\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2628, -1.2971, -1.0516], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0073, 0.0106, 0.0120], grad_fn=<SoftplusBackward0>)\n",
      "step 4700 loss = 6086\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2607, -1.2948, -1.0493], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0072, 0.0103, 0.0117], grad_fn=<SoftplusBackward0>)\n",
      "step 4800 loss = 6089\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2608, -1.3009, -1.0525], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0070, 0.0100, 0.0114], grad_fn=<SoftplusBackward0>)\n",
      "step 4900 loss = 6083\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2599, -1.3027, -1.0504], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0068, 0.0098, 0.0111], grad_fn=<SoftplusBackward0>)\n",
      "step 5000 loss = 6081\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2440, -1.2924, -1.0504], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0066, 0.0095, 0.0107], grad_fn=<SoftplusBackward0>)\n",
      "step 5100 loss = 6078\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2687, -1.2970, -1.0449], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0064, 0.0093, 0.0104], grad_fn=<SoftplusBackward0>)\n",
      "step 5200 loss = 6079\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2627, -1.2997, -1.0469], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0062, 0.0090, 0.0101], grad_fn=<SoftplusBackward0>)\n",
      "step 5300 loss = 6081\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2617, -1.2990, -1.0469], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0061, 0.0088, 0.0098], grad_fn=<SoftplusBackward0>)\n",
      "step 5400 loss = 6080\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2479, -1.2990, -1.0455], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0059, 0.0085, 0.0096], grad_fn=<SoftplusBackward0>)\n",
      "step 5500 loss = 6083\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2581, -1.2968, -1.0476], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0058, 0.0083, 0.0094], grad_fn=<SoftplusBackward0>)\n",
      "step 5600 loss = 6092\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2573, -1.3010, -1.0544], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0056, 0.0081, 0.0091], grad_fn=<SoftplusBackward0>)\n",
      "step 5700 loss = 6086\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2587, -1.2944, -1.0475], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0055, 0.0078, 0.0089], grad_fn=<SoftplusBackward0>)\n",
      "step 5800 loss = 6081\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2557, -1.3003, -1.0483], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0054, 0.0076, 0.0087], grad_fn=<SoftplusBackward0>)\n",
      "step 5900 loss = 6075\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2547, -1.2923, -1.0483], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0052, 0.0074, 0.0085], grad_fn=<SoftplusBackward0>)\n",
      "step 6000 loss = 6076\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2581, -1.3014, -1.0475], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0051, 0.0073, 0.0083], grad_fn=<SoftplusBackward0>)\n",
      "step 6100 loss = 6079\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2658, -1.2979, -1.0487], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0050, 0.0071, 0.0080], grad_fn=<SoftplusBackward0>)\n",
      "step 6200 loss = 6075\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2603, -1.2981, -1.0427], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0048, 0.0069, 0.0079], grad_fn=<SoftplusBackward0>)\n",
      "step 6300 loss = 6075\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2587, -1.2949, -1.0402], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0047, 0.0068, 0.0076], grad_fn=<SoftplusBackward0>)\n",
      "step 6400 loss = 6081\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2651, -1.2951, -1.0390], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0045, 0.0066, 0.0074], grad_fn=<SoftplusBackward0>)\n",
      "step 6500 loss = 6076\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2550, -1.2979, -1.0486], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0045, 0.0064, 0.0072], grad_fn=<SoftplusBackward0>)\n",
      "step 6600 loss = 6077\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2558, -1.2950, -1.0463], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0044, 0.0062, 0.0070], grad_fn=<SoftplusBackward0>)\n",
      "step 6700 loss = 6076\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2651, -1.2940, -1.0451], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0043, 0.0060, 0.0069], grad_fn=<SoftplusBackward0>)\n",
      "step 6800 loss = 6075\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2594, -1.2978, -1.0466], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0041, 0.0059, 0.0067], grad_fn=<SoftplusBackward0>)\n",
      "step 6900 loss = 6084\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2575, -1.2933, -1.0403], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0040, 0.0058, 0.0065], grad_fn=<SoftplusBackward0>)\n",
      "step 7000 loss = 6075\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2634, -1.2992, -1.0460], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0039, 0.0056, 0.0063], grad_fn=<SoftplusBackward0>)\n",
      "step 7100 loss = 6076\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2615, -1.2958, -1.0427], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0038, 0.0055, 0.0062], grad_fn=<SoftplusBackward0>)\n",
      "step 7200 loss = 6075\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2602, -1.2966, -1.0449], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0037, 0.0054, 0.0061], grad_fn=<SoftplusBackward0>)\n",
      "step 7300 loss = 6075\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2545, -1.2982, -1.0458], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0037, 0.0053, 0.0059], grad_fn=<SoftplusBackward0>)\n",
      "step 7400 loss = 6076\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2670, -1.2950, -1.0455], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0036, 0.0051, 0.0058], grad_fn=<SoftplusBackward0>)\n",
      "step 7500 loss = 6076\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2533, -1.2977, -1.0446], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0035, 0.0050, 0.0056], grad_fn=<SoftplusBackward0>)\n",
      "step 7600 loss = 6080\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2613, -1.2966, -1.0440], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0034, 0.0049, 0.0055], grad_fn=<SoftplusBackward0>)\n",
      "step 7700 loss = 6076\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2557, -1.2914, -1.0510], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0034, 0.0048, 0.0054], grad_fn=<SoftplusBackward0>)\n",
      "step 7800 loss = 6077\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2518, -1.2961, -1.0470], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0033, 0.0046, 0.0053], grad_fn=<SoftplusBackward0>)\n",
      "step 7900 loss = 6077\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2634, -1.2986, -1.0461], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0032, 0.0045, 0.0051], grad_fn=<SoftplusBackward0>)\n",
      "step 8000 loss = 6076\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2559, -1.2990, -1.0443], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0032, 0.0044, 0.0050], grad_fn=<SoftplusBackward0>)\n",
      "step 8100 loss = 6076\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2597, -1.3005, -1.0480], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0030, 0.0043, 0.0049], grad_fn=<SoftplusBackward0>)\n",
      "step 8200 loss = 6075\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2585, -1.2954, -1.0433], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0029, 0.0042, 0.0047], grad_fn=<SoftplusBackward0>)\n",
      "step 8300 loss = 6075\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2569, -1.2970, -1.0484], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0029, 0.0041, 0.0046], grad_fn=<SoftplusBackward0>)\n",
      "step 8400 loss = 6075\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2586, -1.2929, -1.0440], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0028, 0.0040, 0.0045], grad_fn=<SoftplusBackward0>)\n",
      "step 8500 loss = 6075\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2598, -1.3023, -1.0453], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0028, 0.0039, 0.0044], grad_fn=<SoftplusBackward0>)\n",
      "step 8600 loss = 6075\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2640, -1.3010, -1.0446], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0027, 0.0038, 0.0043], grad_fn=<SoftplusBackward0>)\n",
      "step 8700 loss = 6077\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2591, -1.3017, -1.0455], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0027, 0.0037, 0.0042], grad_fn=<SoftplusBackward0>)\n",
      "step 8800 loss = 6075\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2529, -1.2995, -1.0501], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0027, 0.0036, 0.0041], grad_fn=<SoftplusBackward0>)\n",
      "step 8900 loss = 6076\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2556, -1.2910, -1.0492], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0026, 0.0035, 0.0040], grad_fn=<SoftplusBackward0>)\n",
      "step 9000 loss = 6075\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2535, -1.2944, -1.0476], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0025, 0.0034, 0.0039], grad_fn=<SoftplusBackward0>)\n",
      "step 9100 loss = 6078\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2592, -1.3014, -1.0463], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0025, 0.0033, 0.0037], grad_fn=<SoftplusBackward0>)\n",
      "step 9200 loss = 6075\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2582, -1.2974, -1.0442], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0024, 0.0032, 0.0036], grad_fn=<SoftplusBackward0>)\n",
      "step 9300 loss = 6075\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2648, -1.2978, -1.0428], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0023, 0.0032, 0.0035], grad_fn=<SoftplusBackward0>)\n",
      "step 9400 loss = 6077\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2519, -1.2984, -1.0488], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0023, 0.0031, 0.0034], grad_fn=<SoftplusBackward0>)\n",
      "step 9500 loss = 6075\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2635, -1.3011, -1.0486], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0022, 0.0030, 0.0034], grad_fn=<SoftplusBackward0>)\n",
      "step 9600 loss = 6075\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2653, -1.3001, -1.0471], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0021, 0.0029, 0.0033], grad_fn=<SoftplusBackward0>)\n",
      "step 9700 loss = 6078\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2538, -1.2986, -1.0457], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0021, 0.0028, 0.0032], grad_fn=<SoftplusBackward0>)\n",
      "step 9800 loss = 6075\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2596, -1.2987, -1.0449], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0020, 0.0028, 0.0031], grad_fn=<SoftplusBackward0>)\n",
      "step 9900 loss = 6075\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "## for a linear layer\n",
    "# class EmbeddingFit(PyroModule):\n",
    "#     def __init__(self, latent_dim, dynamics_model):\n",
    "#         super().__init__()\n",
    "#         self.alpha = PyroSample(dist.Normal(0., 1.).expand([latent_dim]).to_event(1))\n",
    "#         self.weight = copy.deepcopy(dynamics_model.weights.cpu())\n",
    "#         self.bias = copy.deepcopy(dynamics_model.bias.cpu())\n",
    "#         self.sigma = pyro.sample(\"sigma\", dist.Uniform(0., 1.).expand([1]).to_event(1))\n",
    "\n",
    "#     def forward(self, x, output=None):\n",
    "#         batch_size = x.shape[0]\n",
    "#         input = torch.cat((x, self.alpha.repeat([batch_size, 1])), axis=-1)\n",
    "#         mu = input @ self.weight + self.bias\n",
    "#         with pyro.plate(\"instances\", batch_size):\n",
    "#             return pyro.sample(\"obs\", dist.Normal(mu, self.sigma).to_event(1),\n",
    "#                                obs=output)\n",
    "\n",
    "## for the handwritten NN\n",
    "class EmbeddingFit(PyroModule):\n",
    "    def __init__(self, latent_dim, dynamics_model):\n",
    "        super().__init__()\n",
    "        self.alpha = PyroSample(dist.Normal(0., 1.).expand([latent_dim]).to_event(1))\n",
    "        # self.weights1 = copy.deepcopy(dynamics_model.weights1.cpu())\n",
    "        # self.bias1 = copy.deepcopy(dynamics_model.bias1.cpu())\n",
    "        # self.weights2 = copy.deepcopy(dynamics_model.weights2.cpu())\n",
    "        # self.bias2 = copy.deepcopy(dynamics_model.bias2.cpu())\n",
    "        # self.bias2 = torch.randn(11, requires_grad=False)\n",
    "        self.dynamics_model = dynamics_model\n",
    "\n",
    "        # self.sigma = pyro.sample(\"sigma\", dist.Uniform(0., 1.).expand([1]).to_event(1))\n",
    "        self.sigma = pyro.sample(\"sigma\", dist.LogNormal(0., 1.).expand([1]).to_event(1))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, output=None):\n",
    "        batch_size = x.shape[0]\n",
    "        input = torch.cat((x, self.alpha.repeat([batch_size, 1])), axis=-1)\n",
    "        # x = self.relu(input @ self.weights1 + self.bias1)\n",
    "        # mu = x @ self.weights2 + self.bias2\n",
    "        mu = self.dynamics_model(input)\n",
    "        with pyro.plate(\"instances\", batch_size):\n",
    "            return pyro.sample(\"obs\", dist.Normal(mu, 0.01).to_event(1),  # TODO whether 0.01 or self.sigma, self.sigma does not seem to be updated\n",
    "                               obs=output)\n",
    "\n",
    "pyro.clear_param_store() # this is important in notebook; elease memory!\n",
    "# pyro.set_rng_seed(1)\n",
    "\n",
    "dynamics_model = EmbeddingDynamicsNetwork(s_dim, a_dim, latent_dim, hidden_dim=32, hidden_activation=F.relu, output_activation=None, num_hidden_layers=2, lr=1e-2, gamma=0.99).to(device)\n",
    "model_save_path = './model/test/'\n",
    "dynamics_model.load_state_dict(torch.load(model_save_path+'dynamics_model', map_location=device))\n",
    "dynamics_model.eval()\n",
    "for name, param in dynamics_model.named_parameters():\n",
    "    param.requires_grad = False  # this is critical! set not gradient for the trained model, otherwise will be updated in Pyro\n",
    "    # if name == 'bias1':\n",
    "    #     print(name, param)\n",
    "\n",
    "model = EmbeddingFit(latent_dim, dynamics_model)\n",
    "\n",
    "x = test_x\n",
    "y = test_y\n",
    "\n",
    "print(x.shape, y.shape, x.dtype)\n",
    "print(test_x.shape, test_y.shape, test_x.dtype)\n",
    "\n",
    "guide = AutoDiagonalNormal(model)  # posterior dist. before learning AutoDiagonalNormal\n",
    "svi = SVI(model, guide, pyro.optim.Adam({\"lr\": 0.01}), Trace_ELBO())  # parameters to optimize are determined by guide()\n",
    "for step in range(10000):\n",
    "    loss = svi.step(x, y) / y.numel()  # data in step() are passed to both model() and guide()\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        for name, value in pyro.get_param_store().items():\n",
    "            # if name == 'bias2':\n",
    "            print(name, pyro.param(name))\n",
    "        # print(model.dynamics_model.bias1)  # remain unchanged as long as model params requires_grad = False\n",
    "        print(\"step {} loss = {:0.4g}\".format(step, loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.2543, -1.2953, -1.0446], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0020, 0.0027, 0.0031], grad_fn=<SoftplusBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for name, value in pyro.get_param_store().items():\n",
    "    if 'Auto' in name:\n",
    "        print(name, pyro.param(name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.4975, -1.0611, -0.9665], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## true value\n",
    "dynamics_encoder = DynamicsEncoder(param_dim, latent_dim, hidden_dim=32, hidden_activation=F.relu, output_activation=None, num_hidden_layers=4, lr=1e-2, gamma=0.99).to(device)\n",
    "model_save_path = './model/test/'\n",
    "dynamics_encoder.load_state_dict(torch.load(model_save_path+'dynamics_encoder', map_location=device))\n",
    "\n",
    "true_encoding = dynamics_encoder(test_param)\n",
    "print(true_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 23])\n",
      "[[-1.4620235  -0.9292353  -2.3858504  ... -1.5019815  -1.8051643\n",
      "  -2.8081913 ]\n",
      " [ 1.2608469   1.4969504   2.1020446  ...  0.26011953  1.8149033\n",
      "   1.5758591 ]\n",
      " [ 0.79152566  0.92237675  1.3267851  ... -0.35175693  1.1348053\n",
      "   1.0248308 ]\n",
      " [-1.4267539  -0.08124174 -0.70871776 ... -0.19416465 -1.2698132\n",
      "  -1.2513993 ]\n",
      " [-0.23448806 -1.2992532  -0.70612466 ... -2.1950686  -1.2392956\n",
      "   0.31301618]] [[1.4301293  1.3278846  1.8229095  ... 1.5404499  1.7940197  2.0547945 ]\n",
      " [1.4298494  1.1652166  1.8705648  ... 1.3980244  1.4551692  0.9440567 ]\n",
      " [1.0242914  0.63166404 1.1168156  ... 0.56255925 0.6149589  0.73265785]\n",
      " [0.57261705 0.900117   0.68755174 ... 0.5758168  0.8907142  0.9437713 ]\n",
      " [0.91220987 1.0359749  1.8830494  ... 1.6415218  0.8795121  0.97397715]]\n"
     ]
    }
   ],
   "source": [
    "predictive = Predictive(model, guide=guide, num_samples=500)\n",
    "x_test = x_train[:10]\n",
    "print(x_test.shape)\n",
    "preds = predictive(x_test)\n",
    "\n",
    "y_pred = preds['obs'].T.detach().numpy().mean(axis=1)\n",
    "y_std = preds['obs'].T.detach().numpy().std(axis=1)\n",
    "\n",
    "print(y_pred, y_std)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 5))\n",
    "# ax.plot(x, y, 'o', markersize=1)\n",
    "# ax.plot(x_test, y_pred)\n",
    "# ax.fill_between(x_test, y_pred - y_std, y_pred + y_std,\n",
    "#                 alpha=0.5, color='#ffcd3c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(PyroModule):\n",
    "    def __init__(self, h1=20, h2=20):\n",
    "        super().__init__()\n",
    "        self.fc1 = PyroModule[nn.Linear](x_dim, h1)\n",
    "        self.fc1.weight = PyroSample(dist.Normal(0., 1.).expand([h1, x_dim]).to_event(2))\n",
    "        self.fc1.bias = PyroSample(dist.Normal(0., 1.).expand([h1]).to_event(1))\n",
    "        self.fc2 = PyroModule[nn.Linear](h1, h2)\n",
    "        self.fc2.weight = PyroSample(dist.Normal(0., 1.).expand([h2, h1]).to_event(2))\n",
    "        self.fc2.bias = PyroSample(dist.Normal(0., 1.).expand([h2]).to_event(1))\n",
    "        self.fc3 = PyroModule[nn.Linear](h2, y_dim)\n",
    "        self.fc3.weight = PyroSample(dist.Normal(0., 1.).expand([y_dim, h2]).to_event(2))\n",
    "        self.fc3.bias = PyroSample(dist.Normal(0., 1.).expand([y_dim]).to_event(1))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        batch_size = x.shape[0]\n",
    "        # x = x.reshape(-1, 1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        mu = self.fc3(x).squeeze()\n",
    "        sigma = pyro.sample(\"sigma\", dist.Uniform(0., 1.).expand([y_dim]).to_event(1))  # the to_event(1) is necessary, you’ll need to call .to_event(1) to use scalar distributions like Normal as a joint diagonal distributions over multiple variables: see: https://forum.pyro.ai/t/simple-gmm-in-pyro/3047/3\n",
    "        # print(mu.shape, sigma.shape, y.shape)\n",
    "\n",
    "        # with pyro.plate(\"data\", batch_size):\n",
    "        #     obs = pyro.sample(\"obs\", dist.Normal(mu, sigma).to_event(1), obs=y) # the to_event(1) is necessary\n",
    "        #     return mu\n",
    "\n",
    "        with pyro.plate(\"instances\", batch_size):\n",
    "            return pyro.sample(\"obs\", dist.Normal(mu, sigma).to_event(1),\n",
    "                               obs=y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28c6861e59928cb790236f7047915368f37afc12f670e78fd0101a6f825a02b1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('x': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
