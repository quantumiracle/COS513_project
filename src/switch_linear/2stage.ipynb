{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyro-ppl in /home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages (1.8.1)\n",
      "Requirement already satisfied: tqdm>=4.36 in /home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages (from pyro-ppl) (4.62.1)\n",
      "Requirement already satisfied: numpy>=1.7 in /home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages (from pyro-ppl) (1.17.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages (from pyro-ppl) (3.3.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages (from pyro-ppl) (1.11.0)\n",
      "Requirement already satisfied: pyro-api>=0.1.1 in /home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages (from pyro-ppl) (0.1.2)\n",
      "Requirement already satisfied: typing-extensions in /home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages (from torch>=1.11.0->pyro-ppl) (3.10.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyro-ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter dimension:  5\n",
      "number of samples in data:  3549\n",
      "(3549, 11) (3549, 1) (3549, 5) (3549, 11)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = os.path.abspath(os.path.join(os.getcwd(),\"..\"))\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from dynamics_predict.defaults import DYNAMICS_PARAMS, HYPER_PARAMS\n",
    "\n",
    "env_name = 'inverteddoublependulum'\n",
    "data_path = path+'/data/dynamics_data/'+env_name+'/dynamics.npy'\n",
    "param_dim = len(DYNAMICS_PARAMS[env_name+'dynamics'])\n",
    "print('parameter dimension: ', param_dim)\n",
    "\n",
    "train_data = np.load(data_path, allow_pickle=True)\n",
    "print('number of samples in data: ', len(train_data))\n",
    "# split data\n",
    "data_s, data_a, data_param, data_s_ = [], [], [], []\n",
    "for d in train_data:\n",
    "    [s,a,param], s_ = d\n",
    "    data_s.append(s)\n",
    "    data_a.append(a)\n",
    "    data_param.append(param)\n",
    "    data_s_.append(s_)\n",
    "\n",
    "data_s = np.array(data_s)\n",
    "data_a = np.array(data_a)\n",
    "data_param = np.array(data_param)\n",
    "data_s_ = np.array(data_s_)\n",
    "\n",
    "print(data_s.shape, data_a.shape, data_param.shape, data_s_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3549, 12) (3549, 11)\n"
     ]
    }
   ],
   "source": [
    "x = np.concatenate((data_s,data_a), axis=-1)\n",
    "theta = data_param\n",
    "y = data_s_\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "s_dim = data_s.shape[-1]\n",
    "a_dim = data_a.shape[-1]\n",
    "param_dim = data_param.shape[-1]\n",
    "latent_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 95.23431396484375\n",
      "epoch: 100, loss: 1.3649734258651733\n",
      "epoch: 200, loss: 0.6464241743087769\n",
      "epoch: 300, loss: 0.4118870496749878\n",
      "epoch: 400, loss: 0.3060576617717743\n",
      "epoch: 500, loss: 0.2505890130996704\n",
      "epoch: 600, loss: 0.2158588320016861\n",
      "epoch: 700, loss: 0.1919262558221817\n",
      "epoch: 800, loss: 0.17567409574985504\n",
      "epoch: 900, loss: 0.16410739719867706\n",
      "epoch: 1000, loss: 0.15544334053993225\n",
      "epoch: 1100, loss: 0.14852428436279297\n",
      "epoch: 1200, loss: 0.1428985446691513\n",
      "epoch: 1300, loss: 0.13828246295452118\n",
      "epoch: 1400, loss: 0.134075328707695\n",
      "epoch: 1500, loss: 0.13040228188037872\n",
      "epoch: 1600, loss: 0.1269814372062683\n",
      "epoch: 1700, loss: 0.12393048405647278\n",
      "epoch: 1800, loss: 0.1210908517241478\n",
      "epoch: 1900, loss: 0.11828020960092545\n"
     ]
    }
   ],
   "source": [
    "#stage 1, learning forward dynamics and dynamics encoder\n",
    "from torch.distributions import Normal\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "class DynamicsEncoder(nn.Module):\n",
    "    \"\"\" Dynamics parameters encoding network: (params) -> (latent code) \"\"\"\n",
    "    def __init__(self, param_dim, latent_dim, hidden_dim=32, hidden_activation=F.relu, output_activation=F.tanh, num_hidden_layers=2, lr=1e-3, gamma=0.99):\n",
    "        super(DynamicsEncoder, self).__init__()\n",
    "        \n",
    "        self.hidden_activation = hidden_activation\n",
    "        self.output_activation = output_activation\n",
    "        self._param_dim = param_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "\n",
    "        self.input_layer =  nn.Linear(self._param_dim, hidden_dim)\n",
    "        self.hidden_layers = [nn.Linear(hidden_dim, hidden_dim) for _ in range(num_hidden_layers)]\n",
    "        self.hidden_layers = nn.ModuleList(self.hidden_layers)  # Have to wrap the list layers with nn.ModuleList to coorectly make those parameters tracked by nn.module! Otherwise those params will not be saved!\n",
    "        self.output_layer =  nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        # self.scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.99)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.Tensor(x)\n",
    "        x=self.hidden_activation(self.input_layer(x))\n",
    "        for hl in self.hidden_layers:\n",
    "            x=self.hidden_activation(hl(x))\n",
    "        x=self.output_layer(x)\n",
    "        if self.output_activation is not None:\n",
    "            x=self.output_activation(x)\n",
    "        return x\n",
    "\n",
    "## a standard NN\n",
    "# class EmbeddingDynamicsNetwork(nn.Module):\n",
    "#     \"\"\" Common class for dyanmics prediction network with dynamics embedding as input: (s,a, alpha) -> s' \"\"\"\n",
    "#     def __init__(self, s_dim, a_dim, latent_dim, hidden_dim=32, hidden_activation=F.relu, output_activation=F.tanh, num_hidden_layers=2, lr=1e-3, gamma=0.99):\n",
    "#         super(EmbeddingDynamicsNetwork, self).__init__()\n",
    "        \n",
    "#         self.hidden_activation = hidden_activation\n",
    "#         self.output_activation = output_activation\n",
    "#         self.latent_dim = latent_dim\n",
    "#         self.num_hidden_layers = num_hidden_layers\n",
    "\n",
    "#         self.input_layer =  nn.Linear(s_dim+a_dim+self.latent_dim, hidden_dim)\n",
    "#         self.hidden_layers = [nn.Linear(hidden_dim, hidden_dim) for _ in range(num_hidden_layers)]\n",
    "#         self.hidden_layers = nn.ModuleList(self.hidden_layers)  # Have to wrap the list layers with nn.ModuleList to coorectly make those parameters tracked by nn.module! Otherwise those params will not be saved!\n",
    "#         self.output_layer =  nn.Linear(hidden_dim, s_dim)\n",
    "\n",
    "#         self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "#         # self.scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.99)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         if not isinstance(x, torch.Tensor):\n",
    "#             x = torch.Tensor(x)\n",
    "#         x=self.hidden_activation(self.input_layer(x))\n",
    "#         for hl in self.hidden_layers:\n",
    "#             x=self.hidden_activation(hl(x))\n",
    "#         x=self.output_layer(x)\n",
    "#         if self.output_activation is not None:\n",
    "#             x=self.output_activation(x)\n",
    "#         return x\n",
    "\n",
    "## a handwritten NN\n",
    "class EmbeddingDynamicsNetwork(nn.Module):\n",
    "    \"\"\" Common class for dyanmics prediction network with dynamics embedding as input: (s,a, alpha) -> s' \"\"\"\n",
    "    def __init__(self, s_dim, a_dim, latent_dim, hidden_dim=32, hidden_activation=F.relu, output_activation=F.tanh, num_hidden_layers=2, lr=1e-3, gamma=0.99):\n",
    "        super(EmbeddingDynamicsNetwork, self).__init__()\n",
    "        \n",
    "        in_size = s_dim+a_dim+latent_dim\n",
    "        out_size = s_dim\n",
    "\n",
    "        self.weights1 =  nn.Parameter(torch.randn(in_size, hidden_dim))\n",
    "        self.bias1 = nn.Parameter(torch.randn(hidden_dim))\n",
    "        self.weights2 =  nn.Parameter(torch.randn(hidden_dim, out_size))\n",
    "        self.bias2 = nn.Parameter(torch.randn(out_size))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        # self.scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.99)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.Tensor(x)\n",
    "        x = self.relu(x @ self.weights1 + self.bias1)\n",
    "        y = x @ self.weights2 + self.bias2\n",
    "        return y\n",
    "\n",
    "## just a linear layer\n",
    "# class EmbeddingDynamicsNetwork(nn.Module):\n",
    "#     \"\"\" Common class for dyanmics prediction network with dynamics embedding as input: (s,a, alpha) -> s' \"\"\"\n",
    "#     def __init__(self, s_dim, a_dim, latent_dim, hidden_dim=32, hidden_activation=F.relu, output_activation=F.tanh, num_hidden_layers=2, lr=1e-3, gamma=0.99):\n",
    "#         super(EmbeddingDynamicsNetwork, self).__init__()\n",
    "        \n",
    "#         in_size = s_dim+a_dim+latent_dim\n",
    "#         out_size = s_dim\n",
    "\n",
    "#         self.weights =  nn.Parameter(torch.randn(in_size, out_size))\n",
    "#         self.bias = nn.Parameter(torch.randn(out_size))\n",
    "\n",
    "#         self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "#         # self.scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.99)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         if not isinstance(x, torch.Tensor):\n",
    "#             x = torch.Tensor(x)\n",
    "#         y = x @ self.weights + self.bias\n",
    "#         return y\n",
    "\n",
    "class DynamicsParamsOptimizer():\n",
    "    \"\"\" \n",
    "    Dynamics parameters optimization model (gradient-based) based on a trained \n",
    "    forward dynamics prediction network: (s, a, learnable_params) -> s_ with real-world data. \n",
    "    \"\"\"\n",
    "    def __init__(self, s_dim, a_dim, param_dim, latent_dim, hidden_dim=32, hidden_activation=F.relu, output_activation=None, num_hidden_layers=2, lr=1e-2, gamma=0.99):\n",
    "        self.dynamics_model = EmbeddingDynamicsNetwork(s_dim, a_dim, latent_dim, hidden_dim, hidden_activation, output_activation, num_hidden_layers, lr, gamma).to(device)\n",
    "        self.dynamics_encoder = DynamicsEncoder(param_dim, latent_dim, hidden_dim, hidden_activation, output_activation, num_hidden_layers, lr, gamma).to(device)\n",
    "        self.optimizer = torch.optim.Adam(list(self.dynamics_model.parameters()) + list(self.dynamics_encoder.parameters()), lr=lr)\n",
    "\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x, theta):\n",
    "        \"\"\" s,a concat with param (learnable) -> s_ \"\"\"\n",
    "\n",
    "        alpha = self.dynamics_encoder(theta)\n",
    "        y_  = self.dynamics_model(torch.cat((x, alpha), axis=-1))\n",
    "        \n",
    "        return y_\n",
    "\n",
    "    def update(self, data, epoch=200, model_save_path=None):\n",
    "        (x, theta, y) = data\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.Tensor(x).to(device)\n",
    "        if not isinstance(theta, torch.Tensor):\n",
    "            theta = torch.Tensor(theta).to(device)        \n",
    "        if not isinstance(y, torch.Tensor):\n",
    "            y = torch.Tensor(y).to(device)\n",
    "\n",
    "        for ep in range(epoch):\n",
    "            y_ = self.forward(x, theta)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.loss(y_, y)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if ep%100==0:\n",
    "                print('epoch: {}, loss: {}'.format(ep, loss.item()))\n",
    "                torch.save(self.dynamics_model.state_dict(), model_save_path+'dynamics_model')\n",
    "                torch.save(self.dynamics_encoder.state_dict(), model_save_path+'dynamics_encoder')\n",
    "\n",
    "opt = DynamicsParamsOptimizer(s_dim, a_dim, param_dim, latent_dim)\n",
    "data = (x, theta, y)\n",
    "model_save_path = './model/test/'\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "opt.update(data, epoch=2000, model_save_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stage 2, using BNN and SVI to fit alpha\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.nn import PyroModule, PyroSample\n",
    "import torch.nn as nn\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "from pyro.infer import SVI, Trace_ELBO, Predictive\n",
    "from tqdm.auto import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples in dest data:  10\n",
      "(5333, 11) (5333, 1) (5,) (5333, 11)\n"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "test_data_path = path+'/data/dynamics_data/'+env_name+'/test_dynamics.npy'\n",
    "test_data = np.load(test_data_path, allow_pickle=True)\n",
    "print('number of samples in dest data: ', len(test_data))\n",
    "idx=5  # index of sample to test: 0-10\n",
    "test_s = np.array(test_data[idx]['sa'])[:, :-1]\n",
    "test_a = np.array(test_data[idx]['sa'])[:, -1:]\n",
    "test_param = np.array(test_data[idx]['params'])\n",
    "test_s_ = np.array(test_data[idx]['s_'])\n",
    "print(test_s.shape, test_a.shape, test_param.shape, test_s_.shape)\n",
    "\n",
    "# load model\n",
    "# updater = DynamicsParamsOptimizer(state_dim, action_dim, param_dim, latent_dim, switch_dim, model_save_path)\n",
    "# updater.model.load_state_dict(torch.load(model_save_path+'model', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5333, 12]) torch.Size([5333, 11]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "test_x = torch.from_numpy(np.concatenate((test_s,test_a), axis=-1)).float()\n",
    "test_y = torch.from_numpy(test_s_).float()\n",
    "test_param = torch.from_numpy(test_param).float()\n",
    "\n",
    "x_dim = test_x.shape[1]\n",
    "y_dim = test_y.shape[1]\n",
    "print(test_x.shape, test_y.shape, test_param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 12]) torch.Size([100, 11]) torch.float32\n",
      "torch.Size([5333, 12]) torch.Size([5333, 11]) torch.float32\n",
      "step 0 loss = 169.5\n",
      "step 100 loss = 1.105\n",
      "step 200 loss = 0.9408\n",
      "step 300 loss = 0.8202\n",
      "step 400 loss = 0.6255\n",
      "step 500 loss = 0.5359\n",
      "step 600 loss = 0.4901\n",
      "step 700 loss = 0.4174\n",
      "step 800 loss = 0.3353\n",
      "step 900 loss = 0.2755\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "## for a linear layer\n",
    "# class EmbeddingFit(PyroModule):\n",
    "#     def __init__(self, latent_dim, dynamics_model):\n",
    "#         super().__init__()\n",
    "#         self.alpha = PyroSample(dist.Normal(0., 1.).expand([latent_dim]).to_event(1))\n",
    "#         self.weight = copy.deepcopy(dynamics_model.weights.cpu())\n",
    "#         self.bias = copy.deepcopy(dynamics_model.bias.cpu())\n",
    "#         self.sigma = pyro.sample(\"sigma\", dist.Uniform(0., 1.).expand([1]).to_event(1))\n",
    "\n",
    "#     def forward(self, x, output=None):\n",
    "#         batch_size = x.shape[0]\n",
    "#         input = torch.cat((x, self.alpha.repeat([batch_size, 1])), axis=-1)\n",
    "#         mu = input @ self.weight + self.bias\n",
    "#         with pyro.plate(\"instances\", batch_size):\n",
    "#             return pyro.sample(\"obs\", dist.Normal(mu, self.sigma).to_event(1),\n",
    "#                                obs=output)\n",
    "\n",
    "## for the handwritten NN\n",
    "class EmbeddingFit(PyroModule):\n",
    "    def __init__(self, latent_dim, dynamics_model):\n",
    "        super().__init__()\n",
    "        self.alpha = PyroSample(dist.Normal(0., 1.).expand([latent_dim]).to_event(1))\n",
    "        self.weights1 = copy.deepcopy(dynamics_model.weights1.cpu())\n",
    "        self.bias1 = copy.deepcopy(dynamics_model.bias1.cpu())\n",
    "        self.weights2 = copy.deepcopy(dynamics_model.weights2.cpu())\n",
    "        self.bias2 = copy.deepcopy(dynamics_model.bias2.cpu())\n",
    "        self.sigma = pyro.sample(\"sigma\", dist.Uniform(0., 1.).expand([1]).to_event(1))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, output=None):\n",
    "        batch_size = x.shape[0]\n",
    "        input = torch.cat((x, self.alpha.repeat([batch_size, 1])), axis=-1)\n",
    "        x = self.relu(input @ self.weights1 + self.bias1)\n",
    "        mu = x @ self.weights2 + self.bias2\n",
    "        with pyro.plate(\"instances\", batch_size):\n",
    "            return pyro.sample(\"obs\", dist.Normal(mu, self.sigma).to_event(1),\n",
    "                               obs=output)\n",
    "\n",
    "# pyro.clear_param_store()\n",
    "# pyro.set_rng_seed(1)\n",
    "\n",
    "dynamics_model = EmbeddingDynamicsNetwork(s_dim, a_dim, latent_dim, hidden_dim=32, hidden_activation=F.relu, output_activation=None, num_hidden_layers=2, lr=1e-2, gamma=0.99).to(device)\n",
    "model_save_path = './model/test/'\n",
    "dynamics_model.load_state_dict(torch.load(model_save_path+'dynamics_model', map_location=device))\n",
    "\n",
    "model = EmbeddingFit(latent_dim, dynamics_model)\n",
    "\n",
    "x = test_x[:100]\n",
    "y = test_y[:100]\n",
    "\n",
    "print(x.shape, y.shape, x.dtype)\n",
    "print(test_x.shape, test_y.shape, test_x.dtype)\n",
    "\n",
    "guide = AutoDiagonalNormal(model)  # unlearned posterior dist. AutoDiagonalNormal\n",
    "svi = SVI(model, guide, pyro.optim.Adam({\"lr\": 0.01}), Trace_ELBO())  # parameters to optimize are determined by guide()\n",
    "for step in range(1000):\n",
    "    loss = svi.step(x, y) / y.numel()  # data in step() are passed to both model() and guide()\n",
    "    if step % 100 == 0:\n",
    "        # print(model.linear.weight)\n",
    "        print(\"step {} loss = {:0.4g}\".format(step, loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([0.4347, 0.2870], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0209, 0.0138], grad_fn=<SoftplusBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for name, value in pyro.get_param_store().items():\n",
    "    if 'AutoDiagonalNormal' in name:\n",
    "        print(name, pyro.param(name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.6868,  0.3802], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## true value\n",
    "dynamics_encoder = DynamicsEncoder(param_dim, latent_dim, hidden_dim=32, hidden_activation=F.relu, output_activation=None, num_hidden_layers=2, lr=1e-2, gamma=0.99).to(device)\n",
    "model_save_path = './model/test/'\n",
    "dynamics_encoder.load_state_dict(torch.load(model_save_path+'dynamics_encoder', map_location=device))\n",
    "\n",
    "true_encoding = dynamics_encoder(test_param)\n",
    "print(true_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 23])\n",
      "[[-1.4620235  -0.9292353  -2.3858504  ... -1.5019815  -1.8051643\n",
      "  -2.8081913 ]\n",
      " [ 1.2608469   1.4969504   2.1020446  ...  0.26011953  1.8149033\n",
      "   1.5758591 ]\n",
      " [ 0.79152566  0.92237675  1.3267851  ... -0.35175693  1.1348053\n",
      "   1.0248308 ]\n",
      " [-1.4267539  -0.08124174 -0.70871776 ... -0.19416465 -1.2698132\n",
      "  -1.2513993 ]\n",
      " [-0.23448806 -1.2992532  -0.70612466 ... -2.1950686  -1.2392956\n",
      "   0.31301618]] [[1.4301293  1.3278846  1.8229095  ... 1.5404499  1.7940197  2.0547945 ]\n",
      " [1.4298494  1.1652166  1.8705648  ... 1.3980244  1.4551692  0.9440567 ]\n",
      " [1.0242914  0.63166404 1.1168156  ... 0.56255925 0.6149589  0.73265785]\n",
      " [0.57261705 0.900117   0.68755174 ... 0.5758168  0.8907142  0.9437713 ]\n",
      " [0.91220987 1.0359749  1.8830494  ... 1.6415218  0.8795121  0.97397715]]\n"
     ]
    }
   ],
   "source": [
    "predictive = Predictive(model, guide=guide, num_samples=500)\n",
    "x_test = x_train[:10]\n",
    "print(x_test.shape)\n",
    "preds = predictive(x_test)\n",
    "\n",
    "y_pred = preds['obs'].T.detach().numpy().mean(axis=1)\n",
    "y_std = preds['obs'].T.detach().numpy().std(axis=1)\n",
    "\n",
    "print(y_pred, y_std)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 5))\n",
    "# ax.plot(x, y, 'o', markersize=1)\n",
    "# ax.plot(x_test, y_pred)\n",
    "# ax.fill_between(x_test, y_pred - y_std, y_pred + y_std,\n",
    "#                 alpha=0.5, color='#ffcd3c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(PyroModule):\n",
    "    def __init__(self, h1=20, h2=20):\n",
    "        super().__init__()\n",
    "        self.fc1 = PyroModule[nn.Linear](x_dim, h1)\n",
    "        self.fc1.weight = PyroSample(dist.Normal(0., 1.).expand([h1, x_dim]).to_event(2))\n",
    "        self.fc1.bias = PyroSample(dist.Normal(0., 1.).expand([h1]).to_event(1))\n",
    "        self.fc2 = PyroModule[nn.Linear](h1, h2)\n",
    "        self.fc2.weight = PyroSample(dist.Normal(0., 1.).expand([h2, h1]).to_event(2))\n",
    "        self.fc2.bias = PyroSample(dist.Normal(0., 1.).expand([h2]).to_event(1))\n",
    "        self.fc3 = PyroModule[nn.Linear](h2, y_dim)\n",
    "        self.fc3.weight = PyroSample(dist.Normal(0., 1.).expand([y_dim, h2]).to_event(2))\n",
    "        self.fc3.bias = PyroSample(dist.Normal(0., 1.).expand([y_dim]).to_event(1))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        batch_size = x.shape[0]\n",
    "        # x = x.reshape(-1, 1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        mu = self.fc3(x).squeeze()\n",
    "        sigma = pyro.sample(\"sigma\", dist.Uniform(0., 1.).expand([y_dim]).to_event(1))  # the to_event(1) is necessary, youâ€™ll need to call .to_event(1) to use scalar distributions like Normal as a joint diagonal distributions over multiple variables: see: https://forum.pyro.ai/t/simple-gmm-in-pyro/3047/3\n",
    "        # print(mu.shape, sigma.shape, y.shape)\n",
    "\n",
    "        # with pyro.plate(\"data\", batch_size):\n",
    "        #     obs = pyro.sample(\"obs\", dist.Normal(mu, sigma).to_event(1), obs=y) # the to_event(1) is necessary\n",
    "        #     return mu\n",
    "\n",
    "        with pyro.plate(\"instances\", batch_size):\n",
    "            return pyro.sample(\"obs\", dist.Normal(mu, sigma).to_event(1),\n",
    "                               obs=y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28c6861e59928cb790236f7047915368f37afc12f670e78fd0101a6f825a02b1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('x': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
