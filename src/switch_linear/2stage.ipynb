{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyro-ppl in /home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages (1.8.1)\n",
      "Requirement already satisfied: tqdm>=4.36 in /home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages (from pyro-ppl) (4.62.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages (from pyro-ppl) (3.3.0)\n",
      "Requirement already satisfied: pyro-api>=0.1.1 in /home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages (from pyro-ppl) (0.1.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages (from pyro-ppl) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages (from pyro-ppl) (1.17.5)\n",
      "Requirement already satisfied: typing-extensions in /home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages (from torch>=1.11.0->pyro-ppl) (3.10.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyro-ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter dimension:  5\n",
      "number of samples in data:  3549\n",
      "(3549, 11) (3549, 1) (3549, 5) (3549, 11)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = os.path.abspath(os.path.join(os.getcwd(),\"..\"))\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from dynamics_predict.defaults import DYNAMICS_PARAMS, HYPER_PARAMS\n",
    "\n",
    "env_name = 'inverteddoublependulum'\n",
    "data_path = path+'/data/dynamics_data/'+env_name+'/dynamics.npy'\n",
    "param_dim = len(DYNAMICS_PARAMS[env_name+'dynamics'])\n",
    "print('parameter dimension: ', param_dim)\n",
    "\n",
    "train_data = np.load(data_path, allow_pickle=True)\n",
    "print('number of samples in data: ', len(train_data))\n",
    "# split data\n",
    "data_s, data_a, data_param, data_s_ = [], [], [], []\n",
    "for d in train_data:\n",
    "    [s,a,param], s_ = d\n",
    "    data_s.append(s)\n",
    "    data_a.append(a)\n",
    "    data_param.append(param)\n",
    "    data_s_.append(s_)\n",
    "\n",
    "data_s = np.array(data_s)\n",
    "data_a = np.array(data_a)\n",
    "data_param = np.array(data_param)\n",
    "data_s_ = np.array(data_s_)\n",
    "\n",
    "print(data_s.shape, data_a.shape, data_param.shape, data_s_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3549, 12) (3549, 11)\n"
     ]
    }
   ],
   "source": [
    "x = np.concatenate((data_s,data_a), axis=-1)\n",
    "theta = data_param\n",
    "y = data_s_\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "s_dim = data_s.shape[-1]\n",
    "a_dim = data_a.shape[-1]\n",
    "param_dim = data_param.shape[-1]\n",
    "latent_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "class DynamicsEncoder(nn.Module):\n",
    "    \"\"\" Dynamics parameters encoding network: (params) -> (latent code) \"\"\"\n",
    "    def __init__(self, param_dim, latent_dim, hidden_dim=32, hidden_activation=F.relu, output_activation=F.tanh, num_hidden_layers=2, lr=1e-3, gamma=0.99):\n",
    "        super(DynamicsEncoder, self).__init__()\n",
    "        \n",
    "        self.hidden_activation = hidden_activation\n",
    "        self.output_activation = output_activation\n",
    "        self._param_dim = param_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "\n",
    "        self.input_layer =  nn.Linear(self._param_dim, hidden_dim)\n",
    "        self.hidden_layers = [nn.Linear(hidden_dim, hidden_dim) for _ in range(num_hidden_layers)]\n",
    "        self.hidden_layers = nn.ModuleList(self.hidden_layers)  # Have to wrap the list layers with nn.ModuleList to coorectly make those parameters tracked by nn.module! Otherwise those params will not be saved!\n",
    "        self.output_layer =  nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        # self.scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.99)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.Tensor(x)\n",
    "        x=self.hidden_activation(self.input_layer(x))\n",
    "        for hl in self.hidden_layers:\n",
    "            x=self.hidden_activation(hl(x))\n",
    "        x=self.output_layer(x)\n",
    "        if self.output_activation is not None:\n",
    "            x=self.output_activation(x)\n",
    "        return x\n",
    "\n",
    "## a standard NN\n",
    "# class EmbeddingDynamicsNetwork(nn.Module):\n",
    "#     \"\"\" Common class for dyanmics prediction network with dynamics embedding as input: (s,a, alpha) -> s' \"\"\"\n",
    "#     def __init__(self, s_dim, a_dim, latent_dim, hidden_dim=32, hidden_activation=F.relu, output_activation=F.tanh, num_hidden_layers=2, lr=1e-3, gamma=0.99):\n",
    "#         super(EmbeddingDynamicsNetwork, self).__init__()\n",
    "        \n",
    "#         self.hidden_activation = hidden_activation\n",
    "#         self.output_activation = output_activation\n",
    "#         self.latent_dim = latent_dim\n",
    "#         self.num_hidden_layers = num_hidden_layers\n",
    "\n",
    "#         self.input_layer =  nn.Linear(s_dim+a_dim+self.latent_dim, hidden_dim)\n",
    "#         self.hidden_layers = [nn.Linear(hidden_dim, hidden_dim) for _ in range(num_hidden_layers)]\n",
    "#         self.hidden_layers = nn.ModuleList(self.hidden_layers)  # Have to wrap the list layers with nn.ModuleList to coorectly make those parameters tracked by nn.module! Otherwise those params will not be saved!\n",
    "#         self.output_layer =  nn.Linear(hidden_dim, s_dim)\n",
    "\n",
    "#         self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "#         # self.scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.99)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         if not isinstance(x, torch.Tensor):\n",
    "#             x = torch.Tensor(x)\n",
    "#         x=self.hidden_activation(self.input_layer(x))\n",
    "#         for hl in self.hidden_layers:\n",
    "#             x=self.hidden_activation(hl(x))\n",
    "#         x=self.output_layer(x)\n",
    "#         if self.output_activation is not None:\n",
    "#             x=self.output_activation(x)\n",
    "#         return x\n",
    "\n",
    "## a handwritten NN\n",
    "class EmbeddingDynamicsNetwork(nn.Module):\n",
    "    \"\"\" Common class for dyanmics prediction network with dynamics embedding as input: (s,a, alpha) -> s' \"\"\"\n",
    "    def __init__(self, s_dim, a_dim, latent_dim, hidden_dim=32, hidden_activation=F.relu, output_activation=F.tanh, num_hidden_layers=2, lr=1e-3, gamma=0.99):\n",
    "        super(EmbeddingDynamicsNetwork, self).__init__()\n",
    "        \n",
    "        in_size = s_dim+a_dim+latent_dim\n",
    "        out_size = s_dim\n",
    "\n",
    "        self.weights1 =  nn.Parameter(torch.randn(in_size, hidden_dim))\n",
    "        self.bias1 = nn.Parameter(torch.randn(hidden_dim))\n",
    "        self.weights2 =  nn.Parameter(torch.randn(hidden_dim, out_size))\n",
    "        self.bias2 = nn.Parameter(torch.randn(out_size))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        # self.scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.99)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.Tensor(x)\n",
    "        x = self.relu(x @ self.weights1 + self.bias1)\n",
    "        y = x @ self.weights2 + self.bias2\n",
    "        return y\n",
    "\n",
    "## just a linear layer\n",
    "# class EmbeddingDynamicsNetwork(nn.Module):\n",
    "#     \"\"\" Common class for dyanmics prediction network with dynamics embedding as input: (s,a, alpha) -> s' \"\"\"\n",
    "#     def __init__(self, s_dim, a_dim, latent_dim, hidden_dim=32, hidden_activation=F.relu, output_activation=F.tanh, num_hidden_layers=2, lr=1e-3, gamma=0.99):\n",
    "#         super(EmbeddingDynamicsNetwork, self).__init__()\n",
    "        \n",
    "#         in_size = s_dim+a_dim+latent_dim\n",
    "#         out_size = s_dim\n",
    "\n",
    "#         self.weights =  nn.Parameter(torch.randn(in_size, out_size))\n",
    "#         self.bias = nn.Parameter(torch.randn(out_size))\n",
    "\n",
    "#         self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "#         # self.scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.99)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         if not isinstance(x, torch.Tensor):\n",
    "#             x = torch.Tensor(x)\n",
    "#         y = x @ self.weights + self.bias\n",
    "#         return y\n",
    "\n",
    "class DynamicsParamsOptimizer():\n",
    "    \"\"\" \n",
    "    Dynamics parameters optimization model (gradient-based) based on a trained \n",
    "    forward dynamics prediction network: (s, a, learnable_params) -> s_ with real-world data. \n",
    "    \"\"\"\n",
    "    def __init__(self, s_dim, a_dim, param_dim, latent_dim, hidden_dim=32, hidden_activation=F.relu, output_activation=None, num_hidden_layers=2, lr=1e-2, gamma=0.99):\n",
    "        self.dynamics_model = EmbeddingDynamicsNetwork(s_dim, a_dim, latent_dim, hidden_dim, hidden_activation, output_activation, num_hidden_layers, lr, gamma).to(device)\n",
    "        self.dynamics_encoder = DynamicsEncoder(param_dim, latent_dim, hidden_dim, hidden_activation, output_activation, num_hidden_layers, lr, gamma).to(device)\n",
    "        self.optimizer = torch.optim.Adam(list(self.dynamics_model.parameters()) + list(self.dynamics_encoder.parameters()), lr=lr)\n",
    "\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x, theta):\n",
    "        \"\"\" s,a concat with param (learnable) -> s_ \"\"\"\n",
    "\n",
    "        alpha = self.dynamics_encoder(theta)\n",
    "        y_  = self.dynamics_model(torch.cat((x, alpha), axis=-1))\n",
    "        \n",
    "        return y_\n",
    "\n",
    "    def update(self, data, epoch=200, model_save_path=None):\n",
    "        (x, theta, y) = data\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.Tensor(x).to(device)\n",
    "        if not isinstance(theta, torch.Tensor):\n",
    "            theta = torch.Tensor(theta).to(device)        \n",
    "        if not isinstance(y, torch.Tensor):\n",
    "            y = torch.Tensor(y).to(device)\n",
    "\n",
    "        for ep in range(epoch):\n",
    "            y_ = self.forward(x, theta)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.loss(y_, y)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if ep%100==0:\n",
    "                print('epoch: {}, loss: {}'.format(ep, loss.item()))\n",
    "                torch.save(self.dynamics_model.state_dict(), model_save_path+'dynamics_model')\n",
    "                torch.save(self.dynamics_encoder.state_dict(), model_save_path+'dynamics_encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 153.38121032714844\n",
      "epoch: 100, loss: 2.048553705215454\n",
      "epoch: 200, loss: 0.9408065676689148\n",
      "epoch: 300, loss: 0.6003185510635376\n",
      "epoch: 400, loss: 0.4563097059726715\n",
      "epoch: 500, loss: 0.3664354979991913\n",
      "epoch: 600, loss: 0.30238857865333557\n",
      "epoch: 700, loss: 0.2539259195327759\n",
      "epoch: 800, loss: 0.22015471756458282\n",
      "epoch: 900, loss: 0.19902829825878143\n",
      "epoch: 1000, loss: 0.18519233167171478\n",
      "epoch: 1100, loss: 0.1749226599931717\n",
      "epoch: 1200, loss: 0.16718044877052307\n",
      "epoch: 1300, loss: 0.16075584292411804\n",
      "epoch: 1400, loss: 0.15416094660758972\n",
      "epoch: 1500, loss: 0.1488868147134781\n",
      "epoch: 1600, loss: 0.14406649768352509\n",
      "epoch: 1700, loss: 0.1400667428970337\n",
      "epoch: 1800, loss: 0.13641862571239471\n",
      "epoch: 1900, loss: 0.13294389843940735\n",
      "epoch: 2000, loss: 0.12990282475948334\n",
      "epoch: 2100, loss: 0.1271929293870926\n",
      "epoch: 2200, loss: 0.12473718822002411\n",
      "epoch: 2300, loss: 0.12244393676519394\n",
      "epoch: 2400, loss: 0.12024980783462524\n",
      "epoch: 2500, loss: 0.11814117431640625\n",
      "epoch: 2600, loss: 0.11546111106872559\n",
      "epoch: 2700, loss: 0.11253650486469269\n",
      "epoch: 2800, loss: 0.10983020812273026\n",
      "epoch: 2900, loss: 0.10674619674682617\n",
      "epoch: 3000, loss: 0.10333669185638428\n",
      "epoch: 3100, loss: 0.09896095097064972\n",
      "epoch: 3200, loss: 0.09459051489830017\n",
      "epoch: 3300, loss: 0.08804555237293243\n",
      "epoch: 3400, loss: 0.07605969905853271\n",
      "epoch: 3500, loss: 0.06774143129587173\n",
      "epoch: 3600, loss: 0.062290992587804794\n",
      "epoch: 3700, loss: 0.057190582156181335\n",
      "epoch: 3800, loss: 0.05332237109541893\n",
      "epoch: 3900, loss: 0.05031108856201172\n",
      "epoch: 4000, loss: 0.04908856377005577\n",
      "epoch: 4100, loss: 0.045402105897665024\n",
      "epoch: 4200, loss: 0.043365105986595154\n",
      "epoch: 4300, loss: 0.041511546820402145\n",
      "epoch: 4400, loss: 0.04070667177438736\n",
      "epoch: 4500, loss: 0.038407232612371445\n",
      "epoch: 4600, loss: 0.038327813148498535\n",
      "epoch: 4700, loss: 0.03555692359805107\n",
      "epoch: 4800, loss: 0.03558710962533951\n",
      "epoch: 4900, loss: 0.033454447984695435\n",
      "epoch: 5000, loss: 0.03282357379794121\n",
      "epoch: 5100, loss: 0.03230049088597298\n",
      "epoch: 5200, loss: 0.031007664278149605\n",
      "epoch: 5300, loss: 0.029349638149142265\n",
      "epoch: 5400, loss: 0.029100295156240463\n",
      "epoch: 5500, loss: 0.027824852615594864\n",
      "epoch: 5600, loss: 0.02708115056157112\n",
      "epoch: 5700, loss: 0.027556009590625763\n",
      "epoch: 5800, loss: 0.02469058893620968\n",
      "epoch: 5900, loss: 0.025023194029927254\n",
      "epoch: 6000, loss: 0.0244051031768322\n",
      "epoch: 6100, loss: 0.022454509511590004\n",
      "epoch: 6200, loss: 0.022038264200091362\n",
      "epoch: 6300, loss: 0.021000152453780174\n",
      "epoch: 6400, loss: 0.020893150940537453\n",
      "epoch: 6500, loss: 0.01957164891064167\n",
      "epoch: 6600, loss: 0.019624389708042145\n",
      "epoch: 6700, loss: 0.018125545233488083\n",
      "epoch: 6800, loss: 0.017693275585770607\n",
      "epoch: 6900, loss: 0.018453499302268028\n",
      "epoch: 7000, loss: 0.016395723447203636\n",
      "epoch: 7100, loss: 0.017260953783988953\n",
      "epoch: 7200, loss: 0.015645314007997513\n",
      "epoch: 7300, loss: 0.017609043046832085\n",
      "epoch: 7400, loss: 0.016148598864674568\n",
      "epoch: 7500, loss: 0.015060121193528175\n",
      "epoch: 7600, loss: 0.0141917048022151\n",
      "epoch: 7700, loss: 0.013972941786050797\n",
      "epoch: 7800, loss: 0.013901165686547756\n",
      "epoch: 7900, loss: 0.013921776786446571\n",
      "epoch: 8000, loss: 0.01323795598000288\n",
      "epoch: 8100, loss: 0.012989881448447704\n",
      "epoch: 8200, loss: 0.012712138704955578\n",
      "epoch: 8300, loss: 0.014725509099662304\n",
      "epoch: 8400, loss: 0.013107544742524624\n",
      "epoch: 8500, loss: 0.011972769163548946\n",
      "epoch: 8600, loss: 0.01184834074229002\n",
      "epoch: 8700, loss: 0.01177122350782156\n",
      "epoch: 8800, loss: 0.012438631616532803\n",
      "epoch: 8900, loss: 0.011640663258731365\n",
      "epoch: 9000, loss: 0.010809119790792465\n",
      "epoch: 9100, loss: 0.01131453923881054\n",
      "epoch: 9200, loss: 0.010517380200326443\n",
      "epoch: 9300, loss: 0.012021871283650398\n",
      "epoch: 9400, loss: 0.009856115095317364\n",
      "epoch: 9500, loss: 0.010968388058245182\n",
      "epoch: 9600, loss: 0.010930120944976807\n",
      "epoch: 9700, loss: 0.009380485862493515\n",
      "epoch: 9800, loss: 0.009180333465337753\n",
      "epoch: 9900, loss: 0.009556112810969353\n",
      "epoch: 10000, loss: 0.00935105700045824\n",
      "epoch: 10100, loss: 0.008944227360188961\n",
      "epoch: 10200, loss: 0.008971055969595909\n",
      "epoch: 10300, loss: 0.009920765645802021\n",
      "epoch: 10400, loss: 0.008750400505959988\n",
      "epoch: 10500, loss: 0.008709726855158806\n",
      "epoch: 10600, loss: 0.008822737261652946\n",
      "epoch: 10700, loss: 0.008836719207465649\n",
      "epoch: 10800, loss: 0.008640467189252377\n",
      "epoch: 10900, loss: 0.00841703824698925\n",
      "epoch: 11000, loss: 0.008396083489060402\n",
      "epoch: 11100, loss: 0.009442148730158806\n",
      "epoch: 11200, loss: 0.008297307416796684\n",
      "epoch: 11300, loss: 0.008489571511745453\n",
      "epoch: 11400, loss: 0.009450194425880909\n",
      "epoch: 11500, loss: 0.008199082687497139\n",
      "epoch: 11600, loss: 0.008112771436572075\n",
      "epoch: 11700, loss: 0.00968689750880003\n",
      "epoch: 11800, loss: 0.008405258879065514\n",
      "epoch: 11900, loss: 0.008203688077628613\n",
      "epoch: 12000, loss: 0.007836014963686466\n",
      "epoch: 12100, loss: 0.008093409240245819\n",
      "epoch: 12200, loss: 0.008287937380373478\n",
      "epoch: 12300, loss: 0.0073550487868487835\n",
      "epoch: 12400, loss: 0.007404211442917585\n",
      "epoch: 12500, loss: 0.012243863195180893\n",
      "epoch: 12600, loss: 0.007992931641638279\n",
      "epoch: 12700, loss: 0.008597036823630333\n",
      "epoch: 12800, loss: 0.007107737939804792\n",
      "epoch: 12900, loss: 0.007295886054635048\n",
      "epoch: 13000, loss: 0.007025205064564943\n",
      "epoch: 13100, loss: 0.0070116049610078335\n",
      "epoch: 13200, loss: 0.007092003244906664\n",
      "epoch: 13300, loss: 0.00720903929322958\n",
      "epoch: 13400, loss: 0.009838419035077095\n",
      "epoch: 13500, loss: 0.00687214033678174\n",
      "epoch: 13600, loss: 0.006833968218415976\n",
      "epoch: 13700, loss: 0.007629035040736198\n",
      "epoch: 13800, loss: 0.006826809141784906\n",
      "epoch: 13900, loss: 0.006768479011952877\n",
      "epoch: 14000, loss: 0.007534853182733059\n",
      "epoch: 14100, loss: 0.006677031051367521\n",
      "epoch: 14200, loss: 0.006723983213305473\n",
      "epoch: 14300, loss: 0.006990025285631418\n",
      "epoch: 14400, loss: 0.006918536499142647\n",
      "epoch: 14500, loss: 0.007416887208819389\n",
      "epoch: 14600, loss: 0.007206686306744814\n",
      "epoch: 14700, loss: 0.0065916008315980434\n",
      "epoch: 14800, loss: 0.00943949818611145\n",
      "epoch: 14900, loss: 0.006863110698759556\n",
      "epoch: 15000, loss: 0.006575855892151594\n",
      "epoch: 15100, loss: 0.006513012573122978\n",
      "epoch: 15200, loss: 0.006469331216067076\n",
      "epoch: 15300, loss: 0.006408281624317169\n",
      "epoch: 15400, loss: 0.006410696543753147\n",
      "epoch: 15500, loss: 0.006372994743287563\n",
      "epoch: 15600, loss: 0.007398239802569151\n",
      "epoch: 15700, loss: 0.006329841911792755\n",
      "epoch: 15800, loss: 0.006479556672275066\n",
      "epoch: 15900, loss: 0.006380622740834951\n",
      "epoch: 16000, loss: 0.0062675816006958485\n",
      "epoch: 16100, loss: 0.006298327352851629\n",
      "epoch: 16200, loss: 0.0062854397110641\n",
      "epoch: 16300, loss: 0.006668944843113422\n",
      "epoch: 16400, loss: 0.006661959458142519\n",
      "epoch: 16500, loss: 0.006333640310913324\n",
      "epoch: 16600, loss: 0.006338055245578289\n",
      "epoch: 16700, loss: 0.0062911598943173885\n",
      "epoch: 16800, loss: 0.006134621798992157\n",
      "epoch: 16900, loss: 0.006119829136878252\n",
      "epoch: 17000, loss: 0.006333296652883291\n",
      "epoch: 17100, loss: 0.00616204971447587\n",
      "epoch: 17200, loss: 0.008641985245049\n",
      "epoch: 17300, loss: 0.008250187151134014\n",
      "epoch: 17400, loss: 0.00667478097602725\n",
      "epoch: 17500, loss: 0.006169987842440605\n",
      "epoch: 17600, loss: 0.006173731759190559\n",
      "epoch: 17700, loss: 0.007782329339534044\n",
      "epoch: 17800, loss: 0.007134869694709778\n",
      "epoch: 17900, loss: 0.006050131283700466\n",
      "epoch: 18000, loss: 0.008408642373979092\n",
      "epoch: 18100, loss: 0.006003269925713539\n",
      "epoch: 18200, loss: 0.005917583592236042\n",
      "epoch: 18300, loss: 0.0062480103224515915\n",
      "epoch: 18400, loss: 0.0059739090502262115\n",
      "epoch: 18500, loss: 0.0072647808119654655\n",
      "epoch: 18600, loss: 0.00593539047986269\n",
      "epoch: 18700, loss: 0.0069739376194775105\n",
      "epoch: 18800, loss: 0.007529157679527998\n",
      "epoch: 18900, loss: 0.006228375714272261\n",
      "epoch: 19000, loss: 0.005800764076411724\n",
      "epoch: 19100, loss: 0.005788522772490978\n",
      "epoch: 19200, loss: 0.0078085497952997684\n",
      "epoch: 19300, loss: 0.006193291861563921\n",
      "epoch: 19400, loss: 0.00659348675981164\n",
      "epoch: 19500, loss: 0.00642621424049139\n",
      "epoch: 19600, loss: 0.005624827463179827\n",
      "epoch: 19700, loss: 0.005635546520352364\n",
      "epoch: 19800, loss: 0.005586009006947279\n",
      "epoch: 19900, loss: 0.005586961284279823\n"
     ]
    }
   ],
   "source": [
    "#stage 1, learning forward dynamics and dynamics encoder\n",
    "\n",
    "opt = DynamicsParamsOptimizer(s_dim, a_dim, param_dim, latent_dim)\n",
    "data = (x, theta, y)\n",
    "model_save_path = './model/test/'\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "opt.update(data, epoch=20000, model_save_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stage 2, using BNN and SVI to fit alpha\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.nn import PyroModule, PyroSample\n",
    "import torch.nn as nn\n",
    "from pyro.infer.autoguide import AutoNormal, AutoDiagonalNormal\n",
    "from pyro.infer import SVI, Trace_ELBO, Predictive\n",
    "from tqdm.auto import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples in dest data:  10\n",
      "(4401, 11) (4401, 1) (5,) (4401, 11)\n"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "test_data_path = path+'/data/dynamics_data/'+env_name+'/test_dynamics.npy'\n",
    "test_data = np.load(test_data_path, allow_pickle=True)\n",
    "print('number of samples in dest data: ', len(test_data))\n",
    "idx=8  # index of sample to test: 0-10\n",
    "test_s = np.array(test_data[idx]['sa'])[:, :-1]\n",
    "test_a = np.array(test_data[idx]['sa'])[:, -1:]\n",
    "test_param = np.array(test_data[idx]['params'])\n",
    "test_s_ = np.array(test_data[idx]['s_'])\n",
    "print(test_s.shape, test_a.shape, test_param.shape, test_s_.shape)\n",
    "\n",
    "# load model\n",
    "# updater = DynamicsParamsOptimizer(state_dim, action_dim, param_dim, latent_dim, switch_dim, model_save_path)\n",
    "# updater.model.load_state_dict(torch.load(model_save_path+'model', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 12]) torch.Size([1000, 11]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "test_num_samples = 1000\n",
    "test_x = torch.from_numpy(np.concatenate((test_s,test_a), axis=-1)).float()[:test_num_samples]\n",
    "test_y = torch.from_numpy(test_s_).float()[:test_num_samples]\n",
    "test_param = torch.from_numpy(test_param).float()\n",
    "\n",
    "x_dim = test_x.shape[1]\n",
    "y_dim = test_y.shape[1]\n",
    "print(test_x.shape, test_y.shape, test_param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 12]) torch.Size([1000, 11]) torch.float32\n",
      "torch.Size([1000, 12]) torch.Size([1000, 11]) torch.float32\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 0.0586, -0.1217], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0991, 0.1010], grad_fn=<SoftplusBackward0>)\n",
      "step 0 loss = 7.245e+05\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-0.7362, -0.7385], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0886, 0.0878], grad_fn=<SoftplusBackward0>)\n",
      "step 100 loss = 2.129e+05\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-1.1605, -0.8964], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0791, 0.0763], grad_fn=<SoftplusBackward0>)\n",
      "step 200 loss = 5.515e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-1.3813, -0.9548], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0754, 0.0666], grad_fn=<SoftplusBackward0>)\n",
      "step 300 loss = 3.794e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-1.5088, -0.9793], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0739, 0.0594], grad_fn=<SoftplusBackward0>)\n",
      "step 400 loss = 2.94e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-1.6027, -1.0044], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0716, 0.0556], grad_fn=<SoftplusBackward0>)\n",
      "step 500 loss = 2.706e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-1.6740, -1.0306], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0707, 0.0536], grad_fn=<SoftplusBackward0>)\n",
      "step 600 loss = 2.64e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-1.7395, -1.0764], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0702, 0.0521], grad_fn=<SoftplusBackward0>)\n",
      "step 700 loss = 2.807e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-1.8053, -1.1362], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0692, 0.0498], grad_fn=<SoftplusBackward0>)\n",
      "step 800 loss = 2.516e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-1.8631, -1.1977], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0687, 0.0476], grad_fn=<SoftplusBackward0>)\n",
      "step 900 loss = 2.411e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-1.9177, -1.2308], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0679, 0.0451], grad_fn=<SoftplusBackward0>)\n",
      "step 1000 loss = 2.442e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-1.9679, -1.2758], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0674, 0.0430], grad_fn=<SoftplusBackward0>)\n",
      "step 1100 loss = 2.349e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-2.0174, -1.2993], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0671, 0.0400], grad_fn=<SoftplusBackward0>)\n",
      "step 1200 loss = 2.308e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-2.0655, -1.3140], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0668, 0.0377], grad_fn=<SoftplusBackward0>)\n",
      "step 1300 loss = 2.237e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-2.1123, -1.3332], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0669, 0.0360], grad_fn=<SoftplusBackward0>)\n",
      "step 1400 loss = 2.217e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-2.1634, -1.3350], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0665, 0.0343], grad_fn=<SoftplusBackward0>)\n",
      "step 1500 loss = 2.246e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-2.2168, -1.3719], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0664, 0.0332], grad_fn=<SoftplusBackward0>)\n",
      "step 1600 loss = 2.253e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-2.2738, -1.4041], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0661, 0.0323], grad_fn=<SoftplusBackward0>)\n",
      "step 1700 loss = 2.16e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-2.3271, -1.4209], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0655, 0.0315], grad_fn=<SoftplusBackward0>)\n",
      "step 1800 loss = 2.177e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-2.3746, -1.4446], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0651, 0.0309], grad_fn=<SoftplusBackward0>)\n",
      "step 1900 loss = 2.176e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-2.4214, -1.4595], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0647, 0.0303], grad_fn=<SoftplusBackward0>)\n",
      "step 2000 loss = 2.139e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-2.4645, -1.4907], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0643, 0.0301], grad_fn=<SoftplusBackward0>)\n",
      "step 2100 loss = 2.081e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-2.5012, -1.5192], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0638, 0.0298], grad_fn=<SoftplusBackward0>)\n",
      "step 2200 loss = 2.077e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-2.5332, -1.5352], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0631, 0.0294], grad_fn=<SoftplusBackward0>)\n",
      "step 2300 loss = 2.108e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-2.5590, -1.5461], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0624, 0.0291], grad_fn=<SoftplusBackward0>)\n",
      "step 2400 loss = 2.084e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-2.5805, -1.5548], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0616, 0.0288], grad_fn=<SoftplusBackward0>)\n",
      "step 2500 loss = 2.092e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-2.5967, -1.5584], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0610, 0.0287], grad_fn=<SoftplusBackward0>)\n",
      "step 2600 loss = 2.074e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-2.6074, -1.5684], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0603, 0.0286], grad_fn=<SoftplusBackward0>)\n",
      "step 2700 loss = 2.076e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-2.6167, -1.5822], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0595, 0.0283], grad_fn=<SoftplusBackward0>)\n",
      "step 2800 loss = 2.073e+04\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-2.6233, -1.5897], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0587, 0.0282], grad_fn=<SoftplusBackward0>)\n",
      "step 2900 loss = 2.075e+04\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "## for a linear layer\n",
    "# class EmbeddingFit(PyroModule):\n",
    "#     def __init__(self, latent_dim, dynamics_model):\n",
    "#         super().__init__()\n",
    "#         self.alpha = PyroSample(dist.Normal(0., 1.).expand([latent_dim]).to_event(1))\n",
    "#         self.weight = copy.deepcopy(dynamics_model.weights.cpu())\n",
    "#         self.bias = copy.deepcopy(dynamics_model.bias.cpu())\n",
    "#         self.sigma = pyro.sample(\"sigma\", dist.Uniform(0., 1.).expand([1]).to_event(1))\n",
    "\n",
    "#     def forward(self, x, output=None):\n",
    "#         batch_size = x.shape[0]\n",
    "#         input = torch.cat((x, self.alpha.repeat([batch_size, 1])), axis=-1)\n",
    "#         mu = input @ self.weight + self.bias\n",
    "#         with pyro.plate(\"instances\", batch_size):\n",
    "#             return pyro.sample(\"obs\", dist.Normal(mu, self.sigma).to_event(1),\n",
    "#                                obs=output)\n",
    "\n",
    "## for the handwritten NN\n",
    "class EmbeddingFit(PyroModule):\n",
    "    def __init__(self, latent_dim, dynamics_model):\n",
    "        super().__init__()\n",
    "        self.alpha = PyroSample(dist.Normal(0., 1.).expand([latent_dim]).to_event(1))\n",
    "        # self.weights1 = copy.deepcopy(dynamics_model.weights1.cpu())\n",
    "        # self.bias1 = copy.deepcopy(dynamics_model.bias1.cpu())\n",
    "        # self.weights2 = copy.deepcopy(dynamics_model.weights2.cpu())\n",
    "        # self.bias2 = copy.deepcopy(dynamics_model.bias2.cpu())\n",
    "        # self.bias2 = torch.randn(11, requires_grad=False)\n",
    "        self.dynamics_model = dynamics_model\n",
    "\n",
    "        # self.sigma = pyro.sample(\"sigma\", dist.Uniform(0., 1.).expand([1]).to_event(1))\n",
    "        self.sigma = pyro.sample(\"sigma\", dist.LogNormal(0., 1.).expand([1]).to_event(1))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, output=None):\n",
    "        batch_size = x.shape[0]\n",
    "        input = torch.cat((x, self.alpha.repeat([batch_size, 1])), axis=-1)\n",
    "        # x = self.relu(input @ self.weights1 + self.bias1)\n",
    "        # mu = x @ self.weights2 + self.bias2\n",
    "        mu = self.dynamics_model(input)\n",
    "        with pyro.plate(\"instances\", batch_size):\n",
    "            return pyro.sample(\"obs\", dist.Normal(mu, 0.01).to_event(1),  # TODO whether 0.01 or self.sigma, self.sigma does not seem to be updated\n",
    "                               obs=output)\n",
    "\n",
    "pyro.clear_param_store() # this is important in notebook; elease memory!\n",
    "# pyro.set_rng_seed(1)\n",
    "\n",
    "dynamics_model = EmbeddingDynamicsNetwork(s_dim, a_dim, latent_dim, hidden_dim=32, hidden_activation=F.relu, output_activation=None, num_hidden_layers=2, lr=1e-2, gamma=0.99).to(device)\n",
    "model_save_path = './model/test/'\n",
    "dynamics_model.load_state_dict(torch.load(model_save_path+'dynamics_model', map_location=device))\n",
    "dynamics_model.eval()\n",
    "for name, param in dynamics_model.named_parameters():\n",
    "    param.requires_grad = False  # this is critical! set not gradient for the trained model, otherwise will be updated in Pyro\n",
    "    # if name == 'bias1':\n",
    "    #     print(name, param)\n",
    "\n",
    "model = EmbeddingFit(latent_dim, dynamics_model)\n",
    "\n",
    "x = test_x\n",
    "y = test_y\n",
    "\n",
    "print(x.shape, y.shape, x.dtype)\n",
    "print(test_x.shape, test_y.shape, test_x.dtype)\n",
    "\n",
    "guide = AutoDiagonalNormal(model)  # posterior dist. before learning AutoDiagonalNormal\n",
    "svi = SVI(model, guide, pyro.optim.Adam({\"lr\": 0.01}), Trace_ELBO())  # parameters to optimize are determined by guide()\n",
    "for step in range(3000):\n",
    "    loss = svi.step(x, y) / y.numel()  # data in step() are passed to both model() and guide()\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        for name, value in pyro.get_param_store().items():\n",
    "            # if name == 'bias2':\n",
    "            print(name, pyro.param(name))\n",
    "        # print(model.dynamics_model.bias1)  # remain unchanged as long as model params requires_grad = False\n",
    "        print(\"step {} loss = {:0.4g}\".format(step, loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-2.6293, -1.5988], requires_grad=True)\n",
      "AutoDiagonalNormal.scale tensor([0.0580, 0.0280], grad_fn=<SoftplusBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for name, value in pyro.get_param_store().items():\n",
    "    if 'Auto' in name:\n",
    "        print(name, pyro.param(name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.6684, -0.9392], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## true value\n",
    "dynamics_encoder = DynamicsEncoder(param_dim, latent_dim, hidden_dim=32, hidden_activation=F.relu, output_activation=None, num_hidden_layers=2, lr=1e-2, gamma=0.99).to(device)\n",
    "model_save_path = './model/test/'\n",
    "dynamics_encoder.load_state_dict(torch.load(model_save_path+'dynamics_encoder', map_location=device))\n",
    "\n",
    "true_encoding = dynamics_encoder(test_param)\n",
    "print(true_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 23])\n",
      "[[-1.4620235  -0.9292353  -2.3858504  ... -1.5019815  -1.8051643\n",
      "  -2.8081913 ]\n",
      " [ 1.2608469   1.4969504   2.1020446  ...  0.26011953  1.8149033\n",
      "   1.5758591 ]\n",
      " [ 0.79152566  0.92237675  1.3267851  ... -0.35175693  1.1348053\n",
      "   1.0248308 ]\n",
      " [-1.4267539  -0.08124174 -0.70871776 ... -0.19416465 -1.2698132\n",
      "  -1.2513993 ]\n",
      " [-0.23448806 -1.2992532  -0.70612466 ... -2.1950686  -1.2392956\n",
      "   0.31301618]] [[1.4301293  1.3278846  1.8229095  ... 1.5404499  1.7940197  2.0547945 ]\n",
      " [1.4298494  1.1652166  1.8705648  ... 1.3980244  1.4551692  0.9440567 ]\n",
      " [1.0242914  0.63166404 1.1168156  ... 0.56255925 0.6149589  0.73265785]\n",
      " [0.57261705 0.900117   0.68755174 ... 0.5758168  0.8907142  0.9437713 ]\n",
      " [0.91220987 1.0359749  1.8830494  ... 1.6415218  0.8795121  0.97397715]]\n"
     ]
    }
   ],
   "source": [
    "predictive = Predictive(model, guide=guide, num_samples=500)\n",
    "x_test = x_train[:10]\n",
    "print(x_test.shape)\n",
    "preds = predictive(x_test)\n",
    "\n",
    "y_pred = preds['obs'].T.detach().numpy().mean(axis=1)\n",
    "y_std = preds['obs'].T.detach().numpy().std(axis=1)\n",
    "\n",
    "print(y_pred, y_std)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 5))\n",
    "# ax.plot(x, y, 'o', markersize=1)\n",
    "# ax.plot(x_test, y_pred)\n",
    "# ax.fill_between(x_test, y_pred - y_std, y_pred + y_std,\n",
    "#                 alpha=0.5, color='#ffcd3c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(PyroModule):\n",
    "    def __init__(self, h1=20, h2=20):\n",
    "        super().__init__()\n",
    "        self.fc1 = PyroModule[nn.Linear](x_dim, h1)\n",
    "        self.fc1.weight = PyroSample(dist.Normal(0., 1.).expand([h1, x_dim]).to_event(2))\n",
    "        self.fc1.bias = PyroSample(dist.Normal(0., 1.).expand([h1]).to_event(1))\n",
    "        self.fc2 = PyroModule[nn.Linear](h1, h2)\n",
    "        self.fc2.weight = PyroSample(dist.Normal(0., 1.).expand([h2, h1]).to_event(2))\n",
    "        self.fc2.bias = PyroSample(dist.Normal(0., 1.).expand([h2]).to_event(1))\n",
    "        self.fc3 = PyroModule[nn.Linear](h2, y_dim)\n",
    "        self.fc3.weight = PyroSample(dist.Normal(0., 1.).expand([y_dim, h2]).to_event(2))\n",
    "        self.fc3.bias = PyroSample(dist.Normal(0., 1.).expand([y_dim]).to_event(1))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        batch_size = x.shape[0]\n",
    "        # x = x.reshape(-1, 1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        mu = self.fc3(x).squeeze()\n",
    "        sigma = pyro.sample(\"sigma\", dist.Uniform(0., 1.).expand([y_dim]).to_event(1))  # the to_event(1) is necessary, you’ll need to call .to_event(1) to use scalar distributions like Normal as a joint diagonal distributions over multiple variables: see: https://forum.pyro.ai/t/simple-gmm-in-pyro/3047/3\n",
    "        # print(mu.shape, sigma.shape, y.shape)\n",
    "\n",
    "        # with pyro.plate(\"data\", batch_size):\n",
    "        #     obs = pyro.sample(\"obs\", dist.Normal(mu, sigma).to_event(1), obs=y) # the to_event(1) is necessary\n",
    "        #     return mu\n",
    "\n",
    "        with pyro.plate(\"instances\", batch_size):\n",
    "            return pyro.sample(\"obs\", dist.Normal(mu, sigma).to_event(1),\n",
    "                               obs=y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28c6861e59928cb790236f7047915368f37afc12f670e78fd0101a6f825a02b1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('x': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
