{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/quantumiracle/research/COS513_project/src\n",
      "Error: encoder not found!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "path = os.path.abspath(os.path.join(os.getcwd(),\"..\"))\n",
    "print(path)\n",
    "import sys, os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from dynamics_predict.dynamics_networks import DynamicsNetwork, EncoderDynamicsNetwork, EncoderDecoderDynamicsNetwork, VAEDynamicsNetwork\n",
    "from rl.policy_networks import DPG_PolicyNetwork\n",
    "from upesi_utils.load_params import load_params\n",
    "from upesi_utils.common_func import rand_params\n",
    "from dynamics_predict.defaults import DYNAMICS_PARAMS, HYPER_PARAMS\n",
    "from environment import envs\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter dimension:  5\n"
     ]
    }
   ],
   "source": [
    "env_name = 'inverteddoublependulum'\n",
    "data_path = path+'/data/dynamics_data/'+env_name+'/dynamics.npy'\n",
    "param_dim = len(DYNAMICS_PARAMS[env_name+'dynamics'])\n",
    "print('parameter dimension: ', param_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples in data:  174559\n",
      "(100000, 11) (100000, 1) (100000, 5) (100000, 11)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.load(data_path, allow_pickle=True)\n",
    "print('number of samples in data: ', len(train_data))\n",
    "# split data\n",
    "def split_data(data, partial=100000):\n",
    "    data_s, data_a, data_param, data_s_ = [], [], [], []\n",
    "    for d in data[:partial]:\n",
    "        [s,a,param], s_ = d\n",
    "        data_s.append(s)\n",
    "        data_a.append(a)\n",
    "        data_param.append(param)\n",
    "        data_s_.append(s_)\n",
    "\n",
    "    data_s = np.array(data_s)\n",
    "    data_a = np.array(data_a)\n",
    "    data_param = np.array(data_param)\n",
    "    data_s_ = np.array(data_s_)\n",
    "    \n",
    "    return data_s, data_a, data_param, data_s_\n",
    "\n",
    "data_s, data_a, data_param, data_s_ = split_data(train_data)\n",
    "print(data_s.shape, data_a.shape, data_param.shape, data_s_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim = data_s.shape[1]\n",
    "action_dim = data_a.shape[1]\n",
    "param_dim = data_param.shape[1]\n",
    "latent_dim = 2\n",
    "switch_dim = 5\n",
    "\n",
    "model_save_path = f'../data/weights/dynamics/inverteddoublependulum/'\n",
    "os.makedirs(model_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switch Linear Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "class DynamicsParamsOptimizer():\n",
    "    \"\"\" \n",
    "    Dynamics parameters optimization model (gradient-based) based on a trained \n",
    "    forward dynamics prediction network: (s, a, learnable_params) -> s_ with real-world data. \n",
    "    \"\"\"\n",
    "    def __init__(self, state_dim, action_dim, param_dim, latent_dim, switch_dim, model_save_path):\n",
    "        self.model = SLDynamicsNetwork(state_dim, action_dim, param_dim, latent_dim, switch_dim).to(device)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.model_save_path = model_save_path\n",
    "\n",
    "    def train(self, s, a, theta, s_, epoch):\n",
    "        \"\"\" s,a concat with param (learnable) -> s_ \"\"\"\n",
    "        if not isinstance(s_, torch.Tensor):\n",
    "            s_ = torch.Tensor(s_).to(device)\n",
    "        lr_schedule_step = int(epoch/10)  # decay lr for training;  step the scheduler every n epochs\n",
    "\n",
    "        for ep in range(epoch):\n",
    "            s_pred = self.model.forward(s, a, theta)\n",
    "            self.model.optimizer.zero_grad()\n",
    "            loss = self.criterion(s_pred, s_)\n",
    "            loss.backward()\n",
    "            self.model.optimizer.step()\n",
    "            if ep%100==0:\n",
    "                print('epoch: {}, loss: {}'.format(ep, loss.item()))\n",
    "                torch.save(self.model.state_dict(), self.model_save_path+'model')\n",
    "            \n",
    "\n",
    "class SLDynamicsNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, param_dim, latent_dim, switch_dim, lr=1e-4):\n",
    "        super(SLDynamicsNetwork, self).__init__()\n",
    "        self.state_dim = state_dim\n",
    "        self.A = nn.Parameter(torch.rand((switch_dim, latent_dim, state_dim, state_dim)), requires_grad=True)\n",
    "        self.B = nn.Parameter(torch.rand((switch_dim, latent_dim, state_dim, action_dim)), requires_grad=True)\n",
    "        self.E = nn.Parameter(torch.rand((param_dim, latent_dim)), requires_grad=True)\n",
    "        self.switch_logits = nn.Sequential(\n",
    "            nn.Linear(state_dim, switch_dim, bias=False)  # only weight matrix, no bias\n",
    "        )\n",
    "        # print(dict(self.named_parameters()))\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "\n",
    "    def gaussian_noise(self, shape, scale):\n",
    "        normal = Normal(0, 1)\n",
    "        epsilon = scale * normal.sample(shape) \n",
    "        return epsilon\n",
    "\n",
    "    def get_switch_var(self, s):\n",
    "        logits_ = self.switch_logits(s)\n",
    "        switch_var = F.gumbel_softmax(logits_, tau=1, hard=True)  # if hard, return one-hot\n",
    "        return switch_var\n",
    "\n",
    "    def get_s_before_encode(self, s, a):\n",
    "        switch_var = self.get_switch_var(s)\n",
    "        A_w = torch.einsum('ab,bcde->acde', switch_var, self.A) # chosen by the switch variable; shape (#batch, #latent, #state, #state)\n",
    "        B_w = torch.einsum('ab,bcde->acde', switch_var, self.B) # chosen by the switch variable; shape (#batch, #latent, #state, #action)\n",
    "        s_before_encode = torch.einsum('abcd,ad->abc', A_w, s) + torch.einsum('abcd,ad->abc', B_w, a)  # shape (#batch, #latent, #state)\n",
    "        return s_before_encode\n",
    "\n",
    "    def forward(self, s, a, theta):\n",
    "        if not isinstance(s, torch.Tensor):\n",
    "            s = torch.Tensor(s).to(device)\n",
    "        if not isinstance(a, torch.Tensor):\n",
    "            a = torch.Tensor(a).to(device)\n",
    "        if not isinstance(theta, torch.Tensor):\n",
    "            theta = torch.Tensor(theta).to(device)\n",
    "        batch_size = s.shape[0]\n",
    "\n",
    "        s_before_encode = self.get_s_before_encode(s, a)\n",
    "        s_before_noise = torch.einsum('ab,abc->ac', theta@self.E, s_before_encode)  # shape (#batch, #state)\n",
    "        noise = self.gaussian_noise(shape=(batch_size, self.state_dim), scale=0.)\n",
    "        s_ = s_before_noise + noise.to(device)\n",
    "\n",
    "        return s_\n",
    "\n",
    "    def get_latent_code(self, s, a, s_):\n",
    "        if not isinstance(s, torch.Tensor):\n",
    "            s = torch.Tensor(s).to(device).to(device)\n",
    "        if not isinstance(a, torch.Tensor):\n",
    "            a = torch.Tensor(a).to(device)        \n",
    "        if not isinstance(s_, torch.Tensor):\n",
    "            s_ = torch.Tensor(s_).to(device)     \n",
    "\n",
    "        s_before_encode = self.get_s_before_encode(s, a)\n",
    "        inv_s = torch.linalg.pinv(s_before_encode)  # pseudo-inverse; shape (#batch, #state, #latent)\n",
    "        alpha = torch.einsum('ab,abc->ac', s_, inv_s)\n",
    "        print(s_before_encode.shape, inv_s.shape, alpha.shape)\n",
    "\n",
    "        return alpha\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 539.7100830078125\n",
      "epoch: 100, loss: 491.32183837890625\n",
      "epoch: 200, loss: 450.0368957519531\n",
      "epoch: 300, loss: 411.6595764160156\n",
      "epoch: 400, loss: 376.57781982421875\n",
      "epoch: 500, loss: 345.4649963378906\n",
      "epoch: 600, loss: 318.4231872558594\n",
      "epoch: 700, loss: 293.7621765136719\n",
      "epoch: 800, loss: 269.6041259765625\n",
      "epoch: 900, loss: 247.4830780029297\n",
      "epoch: 1000, loss: 229.0004425048828\n",
      "epoch: 1100, loss: 210.2208709716797\n",
      "epoch: 1200, loss: 194.79624938964844\n",
      "epoch: 1300, loss: 178.97267150878906\n",
      "epoch: 1400, loss: 165.9069366455078\n",
      "epoch: 1500, loss: 152.97463989257812\n",
      "epoch: 1600, loss: 142.20616149902344\n",
      "epoch: 1700, loss: 131.77296447753906\n",
      "epoch: 1800, loss: 122.89441680908203\n",
      "epoch: 1900, loss: 113.36376953125\n",
      "epoch: 2000, loss: 106.1604232788086\n",
      "epoch: 2100, loss: 97.84198760986328\n",
      "epoch: 2200, loss: 91.37669372558594\n",
      "epoch: 2300, loss: 85.17292785644531\n",
      "epoch: 2400, loss: 78.93244934082031\n",
      "epoch: 2500, loss: 73.37200164794922\n",
      "epoch: 2600, loss: 68.27425384521484\n",
      "epoch: 2700, loss: 63.59600830078125\n",
      "epoch: 2800, loss: 59.386234283447266\n",
      "epoch: 2900, loss: 55.77633285522461\n",
      "epoch: 3000, loss: 51.953369140625\n",
      "epoch: 3100, loss: 48.319759368896484\n",
      "epoch: 3200, loss: 45.69688034057617\n",
      "epoch: 3300, loss: 42.189876556396484\n",
      "epoch: 3400, loss: 39.84912872314453\n",
      "epoch: 3500, loss: 37.17891311645508\n",
      "epoch: 3600, loss: 34.34666061401367\n",
      "epoch: 3700, loss: 32.26581573486328\n",
      "epoch: 3800, loss: 30.263442993164062\n",
      "epoch: 3900, loss: 28.36861801147461\n",
      "epoch: 4000, loss: 26.539060592651367\n",
      "epoch: 4100, loss: 24.82319450378418\n",
      "epoch: 4200, loss: 23.180923461914062\n",
      "epoch: 4300, loss: 21.998760223388672\n",
      "epoch: 4400, loss: 20.691967010498047\n",
      "epoch: 4500, loss: 19.573040008544922\n",
      "epoch: 4600, loss: 18.044328689575195\n",
      "epoch: 4700, loss: 17.05744171142578\n",
      "epoch: 4800, loss: 16.136442184448242\n",
      "epoch: 4900, loss: 15.1747465133667\n",
      "epoch: 5000, loss: 14.416600227355957\n",
      "epoch: 5100, loss: 13.2804536819458\n",
      "epoch: 5200, loss: 12.699938774108887\n",
      "epoch: 5300, loss: 11.952630996704102\n",
      "epoch: 5400, loss: 11.05713939666748\n",
      "epoch: 5500, loss: 10.720305442810059\n",
      "epoch: 5600, loss: 10.01020336151123\n",
      "epoch: 5700, loss: 9.384965896606445\n",
      "epoch: 5800, loss: 8.971858024597168\n",
      "epoch: 5900, loss: 8.429454803466797\n",
      "epoch: 6000, loss: 7.837912559509277\n",
      "epoch: 6100, loss: 7.541841983795166\n",
      "epoch: 6200, loss: 6.980147361755371\n",
      "epoch: 6300, loss: 6.680309772491455\n",
      "epoch: 6400, loss: 6.376638889312744\n",
      "epoch: 6500, loss: 5.9611124992370605\n",
      "epoch: 6600, loss: 5.638993263244629\n",
      "epoch: 6700, loss: 5.3599724769592285\n",
      "epoch: 6800, loss: 5.042427062988281\n",
      "epoch: 6900, loss: 4.744070529937744\n",
      "epoch: 7000, loss: 4.489196300506592\n",
      "epoch: 7100, loss: 4.346343994140625\n",
      "epoch: 7200, loss: 4.068783760070801\n",
      "epoch: 7300, loss: 3.9425277709960938\n",
      "epoch: 7400, loss: 3.7820699214935303\n",
      "epoch: 7500, loss: 3.4811511039733887\n",
      "epoch: 7600, loss: 3.3101367950439453\n",
      "epoch: 7700, loss: 3.126457691192627\n",
      "epoch: 7800, loss: 3.0343997478485107\n",
      "epoch: 7900, loss: 2.8138904571533203\n",
      "epoch: 8000, loss: 2.707425117492676\n",
      "epoch: 8100, loss: 2.5467846393585205\n",
      "epoch: 8200, loss: 2.4280076026916504\n",
      "epoch: 8300, loss: 2.323133945465088\n",
      "epoch: 8400, loss: 2.208170175552368\n",
      "epoch: 8500, loss: 2.0947930812835693\n",
      "epoch: 8600, loss: 1.9727240800857544\n",
      "epoch: 8700, loss: 1.8786499500274658\n",
      "epoch: 8800, loss: 1.7657972574234009\n",
      "epoch: 8900, loss: 1.7427136898040771\n",
      "epoch: 9000, loss: 1.5981874465942383\n",
      "epoch: 9100, loss: 1.5599104166030884\n",
      "epoch: 9200, loss: 1.472935438156128\n",
      "epoch: 9300, loss: 1.400411605834961\n",
      "epoch: 9400, loss: 1.3587085008621216\n",
      "epoch: 9500, loss: 1.2764456272125244\n",
      "epoch: 9600, loss: 1.1983668804168701\n",
      "epoch: 9700, loss: 1.2016264200210571\n",
      "epoch: 9800, loss: 1.1061042547225952\n",
      "epoch: 9900, loss: 1.0414445400238037\n",
      "epoch: 10000, loss: 0.989454984664917\n",
      "epoch: 10100, loss: 0.965156614780426\n",
      "epoch: 10200, loss: 0.9129836559295654\n",
      "epoch: 10300, loss: 0.8613660335540771\n",
      "epoch: 10400, loss: 0.8394723534584045\n",
      "epoch: 10500, loss: 0.8122382760047913\n",
      "epoch: 10600, loss: 0.7802854180335999\n",
      "epoch: 10700, loss: 0.7627103924751282\n",
      "epoch: 10800, loss: 0.711493968963623\n",
      "epoch: 10900, loss: 0.6739213466644287\n",
      "epoch: 11000, loss: 0.6455179452896118\n",
      "epoch: 11100, loss: 0.6200727224349976\n",
      "epoch: 11200, loss: 0.5918813347816467\n",
      "epoch: 11300, loss: 0.5783968567848206\n",
      "epoch: 11400, loss: 0.5503981113433838\n",
      "epoch: 11500, loss: 0.5277271270751953\n",
      "epoch: 11600, loss: 0.5114136338233948\n",
      "epoch: 11700, loss: 0.4926281273365021\n",
      "epoch: 11800, loss: 0.49791431427001953\n",
      "epoch: 11900, loss: 0.46180975437164307\n",
      "epoch: 12000, loss: 0.449327677488327\n",
      "epoch: 12100, loss: 0.4352889358997345\n",
      "epoch: 12200, loss: 0.42822226881980896\n",
      "epoch: 12300, loss: 0.41236647963523865\n",
      "epoch: 12400, loss: 0.3921404778957367\n",
      "epoch: 12500, loss: 0.3831751346588135\n",
      "epoch: 12600, loss: 0.38168904185295105\n",
      "epoch: 12700, loss: 0.3633819818496704\n",
      "epoch: 12800, loss: 0.352706640958786\n",
      "epoch: 12900, loss: 0.3453753888607025\n",
      "epoch: 13000, loss: 0.34669268131256104\n",
      "epoch: 13100, loss: 0.32542192935943604\n",
      "epoch: 13200, loss: 0.3237818777561188\n",
      "epoch: 13300, loss: 0.3133859634399414\n",
      "epoch: 13400, loss: 0.30714869499206543\n",
      "epoch: 13500, loss: 0.3046303391456604\n",
      "epoch: 13600, loss: 0.29808270931243896\n",
      "epoch: 13700, loss: 0.29217538237571716\n",
      "epoch: 13800, loss: 0.2887785732746124\n",
      "epoch: 13900, loss: 0.28297850489616394\n",
      "epoch: 14000, loss: 0.276679128408432\n",
      "epoch: 14100, loss: 0.27492353320121765\n",
      "epoch: 14200, loss: 0.2678055167198181\n",
      "epoch: 14300, loss: 0.2669447958469391\n",
      "epoch: 14400, loss: 0.26575806736946106\n",
      "epoch: 14500, loss: 0.2558259963989258\n",
      "epoch: 14600, loss: 0.25695207715034485\n",
      "epoch: 14700, loss: 0.2512126564979553\n",
      "epoch: 14800, loss: 0.25049033761024475\n",
      "epoch: 14900, loss: 0.24758298695087433\n",
      "epoch: 15000, loss: 0.24432548880577087\n",
      "epoch: 15100, loss: 0.24210576713085175\n",
      "epoch: 15200, loss: 0.2398686707019806\n",
      "epoch: 15300, loss: 0.23577246069908142\n",
      "epoch: 15400, loss: 0.23330146074295044\n",
      "epoch: 15500, loss: 0.23433813452720642\n",
      "epoch: 15600, loss: 0.22909803688526154\n",
      "epoch: 15700, loss: 0.2284039407968521\n",
      "epoch: 15800, loss: 0.22598567605018616\n",
      "epoch: 15900, loss: 0.22324681282043457\n",
      "epoch: 16000, loss: 0.22237171232700348\n",
      "epoch: 16100, loss: 0.22069036960601807\n",
      "epoch: 16200, loss: 0.2178240269422531\n",
      "epoch: 16300, loss: 0.21796077489852905\n",
      "epoch: 16400, loss: 0.21441181004047394\n",
      "epoch: 16500, loss: 0.21146367490291595\n",
      "epoch: 16600, loss: 0.2122870236635208\n",
      "epoch: 16700, loss: 0.20793108642101288\n",
      "epoch: 16800, loss: 0.20781350135803223\n",
      "epoch: 16900, loss: 0.20646090805530548\n",
      "epoch: 17000, loss: 0.20341451466083527\n",
      "epoch: 17100, loss: 0.20205022394657135\n",
      "epoch: 17200, loss: 0.19951164722442627\n",
      "epoch: 17300, loss: 0.1993314027786255\n",
      "epoch: 17400, loss: 0.1975056231021881\n",
      "epoch: 17500, loss: 0.1952602118253708\n",
      "epoch: 17600, loss: 0.1932085007429123\n",
      "epoch: 17700, loss: 0.19266276061534882\n",
      "epoch: 17800, loss: 0.18950530886650085\n",
      "epoch: 17900, loss: 0.18843629956245422\n",
      "epoch: 18000, loss: 0.1868768036365509\n",
      "epoch: 18100, loss: 0.1845201551914215\n",
      "epoch: 18200, loss: 0.18368381261825562\n",
      "epoch: 18300, loss: 0.1816580891609192\n",
      "epoch: 18400, loss: 0.1813267320394516\n",
      "epoch: 18500, loss: 0.1809300035238266\n",
      "epoch: 18600, loss: 0.17643766105175018\n",
      "epoch: 18700, loss: 0.17566238343715668\n",
      "epoch: 18800, loss: 0.17384490370750427\n",
      "epoch: 18900, loss: 0.17238470911979675\n",
      "epoch: 19000, loss: 0.1706993132829666\n",
      "epoch: 19100, loss: 0.16921232640743256\n",
      "epoch: 19200, loss: 0.16801141202449799\n",
      "epoch: 19300, loss: 0.1683252900838852\n",
      "epoch: 19400, loss: 0.1652994006872177\n",
      "epoch: 19500, loss: 0.16472795605659485\n",
      "epoch: 19600, loss: 0.16236330568790436\n",
      "epoch: 19700, loss: 0.1619543433189392\n",
      "epoch: 19800, loss: 0.1609121561050415\n",
      "epoch: 19900, loss: 0.16120633482933044\n",
      "epoch: 20000, loss: 0.15967470407485962\n",
      "epoch: 20100, loss: 0.15659621357917786\n",
      "epoch: 20200, loss: 0.15668432414531708\n",
      "epoch: 20300, loss: 0.15520401298999786\n",
      "epoch: 20400, loss: 0.15470071136951447\n",
      "epoch: 20500, loss: 0.1528748869895935\n",
      "epoch: 20600, loss: 0.15148630738258362\n",
      "epoch: 20700, loss: 0.15211011469364166\n",
      "epoch: 20800, loss: 0.15000876784324646\n",
      "epoch: 20900, loss: 0.15008792281150818\n",
      "epoch: 21000, loss: 0.14966359734535217\n",
      "epoch: 21100, loss: 0.14802522957324982\n",
      "epoch: 21200, loss: 0.14712302386760712\n",
      "epoch: 21300, loss: 0.14573734998703003\n",
      "epoch: 21400, loss: 0.14499081671237946\n",
      "epoch: 21500, loss: 0.14627835154533386\n",
      "epoch: 21600, loss: 0.1440175622701645\n",
      "epoch: 21700, loss: 0.14332041144371033\n",
      "epoch: 21800, loss: 0.14284345507621765\n",
      "epoch: 21900, loss: 0.14244359731674194\n",
      "epoch: 22000, loss: 0.14137601852416992\n",
      "epoch: 22100, loss: 0.14079900085926056\n",
      "epoch: 22200, loss: 0.14062407612800598\n",
      "epoch: 22300, loss: 0.1392502784729004\n",
      "epoch: 22400, loss: 0.13824759423732758\n",
      "epoch: 22500, loss: 0.1390305608510971\n",
      "epoch: 22600, loss: 0.13699619472026825\n",
      "epoch: 22700, loss: 0.13639037311077118\n",
      "epoch: 22800, loss: 0.13523954153060913\n",
      "epoch: 22900, loss: 0.13571572303771973\n",
      "epoch: 23000, loss: 0.13535502552986145\n",
      "epoch: 23100, loss: 0.13456524908542633\n",
      "epoch: 23200, loss: 0.133009135723114\n",
      "epoch: 23300, loss: 0.13345380127429962\n",
      "epoch: 23400, loss: 0.13148941099643707\n",
      "epoch: 23500, loss: 0.1317392885684967\n",
      "epoch: 23600, loss: 0.13168630003929138\n",
      "epoch: 23700, loss: 0.1307346224784851\n",
      "epoch: 23800, loss: 0.13061289489269257\n",
      "epoch: 23900, loss: 0.13058443367481232\n",
      "epoch: 24000, loss: 0.13026686012744904\n",
      "epoch: 24100, loss: 0.1282123178243637\n",
      "epoch: 24200, loss: 0.12827853858470917\n",
      "epoch: 24300, loss: 0.12739335000514984\n",
      "epoch: 24400, loss: 0.12744061648845673\n",
      "epoch: 24500, loss: 0.12691329419612885\n",
      "epoch: 24600, loss: 0.1261325627565384\n",
      "epoch: 24700, loss: 0.12569846212863922\n",
      "epoch: 24800, loss: 0.12663812935352325\n",
      "epoch: 24900, loss: 0.12761148810386658\n",
      "epoch: 25000, loss: 0.12516281008720398\n",
      "epoch: 25100, loss: 0.12457317858934402\n",
      "epoch: 25200, loss: 0.1244167611002922\n",
      "epoch: 25300, loss: 0.1230754405260086\n",
      "epoch: 25400, loss: 0.12528494000434875\n",
      "epoch: 25500, loss: 0.12346266955137253\n",
      "epoch: 25600, loss: 0.12399214506149292\n",
      "epoch: 25700, loss: 0.1230086237192154\n",
      "epoch: 25800, loss: 0.12278616428375244\n",
      "epoch: 25900, loss: 0.12307032942771912\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_266140/1276778218.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mupdater\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDynamicsParamsOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswitch_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mupdater\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_s_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_266140/1481027836.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, s, a, theta, s_, epoch)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/x/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/x/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# train\n",
    "updater = DynamicsParamsOptimizer(state_dim, action_dim, param_dim, latent_dim, switch_dim, model_save_path)\n",
    "updater.train(data_s, data_a, data_param, data_s_, epoch=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "\n",
    "def display_points(predict_x,true_x):\n",
    "#     plt.xlim(0,5)\n",
    "#     plt.ylim(-3,1)\n",
    "    predict_x = np.array(predict_x)\n",
    "    true_x = np.array(true_x)\n",
    "#     colors = get_cmap(predict_x.shape[0])\n",
    "    \n",
    "    for i, (x, x_) in enumerate(zip(predict_x, true_x)):\n",
    "        c=numpy.random.rand(3,)\n",
    "        # plt.scatter(*x, c=c, markersize=10)\n",
    "        # plt.plot(*x_,\"*\", c=c, markersize=8)  \n",
    "        plt.scatter(*x_, color=c, marker=\"*\", s=80, alpha=0.7)\n",
    "        plt.scatter(*x, color=c, s=80, label=i,  alpha=0.7)\n",
    "    plt.xlabel(r'$\\alpha_1$')\n",
    "    plt.ylabel(r'$\\alpha_2$')\n",
    "    plt.legend()\n",
    "    plt.savefig('compare_sld.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples in dest data:  10\n",
      "(5333, 11) (5333, 1) (5,) (5333, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load test data\n",
    "test_data_path = path+'/data/dynamics_data/'+env_name+'/test_dynamics.npy'\n",
    "test_data = np.load(test_data_path, allow_pickle=True)\n",
    "print('number of samples in dest data: ', len(test_data))\n",
    "idx=5  # index of sample to test: 0-10\n",
    "test_s = np.array(test_data[idx]['sa'])[:, :-1]\n",
    "test_a = np.array(test_data[idx]['sa'])[:, -1:]\n",
    "test_param = np.array(test_data[idx]['params'])\n",
    "test_s_ = np.array(test_data[idx]['s_'])\n",
    "print(test_s.shape, test_a.shape, test_param.shape, test_s_.shape)\n",
    "\n",
    "# load model\n",
    "updater = DynamicsParamsOptimizer(state_dim, action_dim, param_dim, latent_dim, switch_dim, model_save_path)\n",
    "updater.model.load_state_dict(torch.load(model_save_path+'model', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 2, 11]) torch.Size([1000, 11, 2]) torch.Size([1000, 2])\n",
      "tensor([[0.8014, 2.8054],\n",
      "        [1.0725, 2.1518],\n",
      "        [0.9140, 2.4149],\n",
      "        ...,\n",
      "        [0.8213, 2.1256],\n",
      "        [0.8427, 2.6282],\n",
      "        [1.0299, 2.1979]], grad_fn=<ViewBackward0>) [0.9603149 2.1877666] [[0.9228211 2.7533677]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_test_data = 1000\n",
    "alpha = updater.model.get_latent_code(test_s[:num_test_data], test_a[:num_test_data], test_s_[:num_test_data])\n",
    "average_alpha = alpha.mean(dim=0).detach().cpu().numpy()\n",
    "\n",
    "# compare with encoded value\n",
    "alpha_ = (torch.Tensor([test_param]).to(device)@updater.model.E).detach().cpu().numpy()\n",
    "print(alpha, average_alpha, alpha_)\n",
    "\n",
    "display_points([average_alpha], alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples in dest data:  10\n"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "test_data_path = path+'/data/dynamics_data/'+env_name+'/test_dynamics.npy'\n",
    "test_data = np.load(test_data_path, allow_pickle=True)\n",
    "print('number of samples in dest data: ', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 2, 11]) torch.Size([40, 11, 2]) torch.Size([40, 2])\n",
      "[0.87254924 2.3232336 ] [0.9297836 2.5999126]\n",
      "torch.Size([40, 2, 11]) torch.Size([40, 11, 2]) torch.Size([40, 2])\n",
      "[0.84321356 2.4151158 ] [0.72224903 3.1760385 ]\n",
      "torch.Size([40, 2, 11]) torch.Size([40, 11, 2]) torch.Size([40, 2])\n",
      "[0.92283404 2.30193   ] [0.9228211 2.7533677]\n",
      "torch.Size([40, 2, 11]) torch.Size([40, 11, 2]) torch.Size([40, 2])\n",
      "[0.8962491 2.4607048] [0.71717197 2.3505447 ]\n",
      "torch.Size([40, 2, 11]) torch.Size([40, 11, 2]) torch.Size([40, 2])\n",
      "[1.2178984 1.3055837] [0.87341046 2.1290832 ]\n",
      "torch.Size([40, 2, 11]) torch.Size([40, 11, 2]) torch.Size([40, 2])\n",
      "[0.8634264 2.4905818] [0.8932072 2.5841868]\n",
      "torch.Size([40, 2, 11]) torch.Size([40, 11, 2]) torch.Size([40, 2])\n",
      "[0.9231141 2.0439532] [0.8413188 2.6488624]\n",
      "torch.Size([40, 2, 11]) torch.Size([40, 11, 2]) torch.Size([40, 2])\n",
      "[0.5691488 2.5848022] [0.6726199 2.286192 ]\n",
      "torch.Size([40, 2, 11]) torch.Size([40, 11, 2]) torch.Size([40, 2])\n",
      "[0.5876991 3.066546 ] [0.6586934 2.9297676]\n",
      "torch.Size([40, 2, 11]) torch.Size([40, 11, 2]) torch.Size([40, 2])\n",
      "[0.9481405 2.1474674] [1.1428808 1.7045168]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA6gElEQVR4nO3de3xU9bn4+8+zZmbN5J4AQYEQLkURAeWm6K7HSxUKHrXbS1utt6rd7OO2e9de9qv78vu1u57To7/d06pt/bXbtthWW6271dZatSK2pVpRuQqKVBQqASoQCAlJZtbMWs/5Y4YYIEySmcxMQp7365UXk3X5ricQ5pnvXVQVY4wx5licUgdgjDFmcLNEYYwxJitLFMYYY7KyRGGMMSYrSxTGGGOyskRhjDEmq4InChGJicgrIrJeRF4Xka/0cM3nROQNEXlNRJaLyIRu53wRWZf5eqLQ8RpjjDmcFHoehYgIUKGqB0UkArwAfEZVV3a75gLgZVXtEJFbgfNV9eOZcwdVtbKgQRpjjDmmcKEfoOlMdDDzbSTzpUdc87tu364Ersv1eaNGjdKJEyfmersxxgxLq1ev3quq9T2dK3iiABCRELAamALcp6ovZ7n8FuDpbt/HRGQVkALuUtVfZnvWxIkTWbVqVZ4RG2PM8CIifznWuaIkClX1gVkiUgs8LiIzVHXjkdeJyHXAPOC8bocnqOoOEZkMPC8iG1T17SPuWwIsAWhsbCzUj2GMMcNSUUc9qWoL8Dtg0ZHnROQi4N+By1Q10e2eHZk/3wF+D8zuodz7VXWeqs6rr++x5mSMMSZHxRj1VJ+pSSAiZcAC4M0jrpkN/BfpJLG72/E6EYlmXo8CPgi8UeiYzdFUlQ1eC7aIpDHDTzGansYAP8r0UzjAo6r6pIjcAaxS1SeArwGVwH+nB0nxrqpeBkwD/ktEgsy9d6mqJYoSaPI7+X8PbORrdXNoCJeXOhxjBqVkMklTUxPxeLzUoRxTLBajoaGBSCTS53uKMerpNXpuLvpSt9cXHePePwEzCxed6atXE83sSsV5NdFsicKYY2hqaqKqqoqJEyeS+dA7qKgqzc3NNDU1MWnSpD7fV5TObDP0eBqwxtuHn2lqei6+i5Ehl2XxXYwOxQAIiTDHHYErNsHfGIB4PD5okwSAiDBy5Ej27NnTr/ssUZgeeRrw8MFtbEweoNaJ4CCMcqLs8RN8o3UTLUGSGZEaZtTVWqIwppvBmiQOySU++x9uelTphLmzbhZ/W96AAtVOBBGh2omgwN+WN3BX3SwqHfusYUyuvM44m37/Kqt/+Tybfv8qXmf+fRvPPPMMU6dOZcqUKdx1110DEKXVKEwW5U6YT1edzJ+TrewPkvgoKVXGhcr4dNXJg/6TkzGDlaqy+vHlLP/Oz0glkgRBgOM4hKMRLrz148y9/MKc/n/5vs9tt93GsmXLaGho4IwzzuCyyy7j1FNPzSteSxQmq71BgndTHTgCZYTp1BRtqSR7gwT1mb4KY0z/rH58OU9//UdUjqyhvLaq63gq4fH0138EwLwrehzjk9Urr7zClClTmDx5MgBXX301v/rVr/JOFNb0ZLJandhHgHJVeSNLR53FleWNBChrEvtKHZoxQ5LXGWf5d35G5cgawlH3sHPhqEvlyBqWf/dRkvHEMUo4th07djB+/Piu7xsaGtixY0feMVuNwmTVGC7nrrpZTHdrAbiuchKz3Tqs0cmY3Lz98gZSieRhNYnuwlGXjgMHefvlDZxy3rwiR9czSxQmq1MzCaK76T0cM8b0TUdLG0EQZL1Gg4D2/a39LnvcuHFs37696/umpibGjRvX73KOZE1PxhhTROW1VThO9rdecRwq6qr7XfYZZ5zBW2+9xdatW/E8j0ceeYTLLrss11C7WI2ijzQVx9uzHk20ItFq3PrTkbB15hpj+ucD82cSjkZIJbyj+iiAruMfmN//RSnC4TDf/va3+fCHP4zv+9x8881Mnz4975gtUfRCVYlve5aOTQ+hQRI0AHEQJ0L5tOuITVxow0SNMX3mlsW48NaPd4166p4sUgmPg/sOsPhzNxKJRXMq/+KLL+biiy8eqHABSxS9im97lvYN38eJ1uK471cF1fdo3/B9AMomfbhU4RljhqC5l18IwPLv/IyOAwfRIEAch7AbYfHnbuw6P1hYoshCU3E6Nj2EE61FQodXESXk4kRr6dj0E2Ljz0fCuWV/Y8zwIyLMu+IiTlt8Du+8spH2/a1U1FXzgfkzc65JFJIliiy8PevRIHlYTaI7CbkEyTa8PeuJjjmzyNEZY4Y6tyw2aIbAZmOjnrLQRGu6TyLrRYomDhQnIGOMKQFLFFlItBp6WxlVBInWFCcgY4wpAUsUWbj1pyNOBPW9Hs+r7yGOi1t/epEjM8aY4rFEkYWEY5RPu44g0XJUslDfI0i0UD7tWuvINsbkJK4+LyX28tvOnbyU2Etc/bzLvPnmmxk9ejQzZswYgAjTCt6ZLSIxYAUQzTzv56r65SOuiQI/BuYCzcDHVXVb5ty/ArcAPvBPqvrbQsfcXWziQgA6Nj1EkGwD1XRzkxOhYuanus4bY0xfqSrPdO7iwfateOoTKDgCroS4vmISi8rG5Dw/65Of/CSf/vSnueGGGwYs3mKMekoAH1LVgyISAV4QkadVdWW3a24B9qvqFBG5GvhfwMdF5FTgamA6MBZ4TkROVh2AtNtHIkLZpA8TG38e3p7X0MQBJFqTmZltNQljTP8907mL+w9uoc5xqXYiXcc9Dbj/4BYAFpePzansc889l23btg1EmF0K3vSkaQcz30YyX3rEZR8BfpR5/XPgQkmn048Aj6hqQlW3AluAkoxDlXCM6JgziU1cQHTMmZYkjDE5iavPg+1bqXPco7YRdsWhznF5sH0rieJ9Hu5VUfooRCQkIuuA3cAyVX35iEvGAdsBVDUFHABGdj+e0ZQ5dmT5S0RklYis6u+m4cYYU0xrvf146h9zr3lXHDz1WevtL3Jkx1aURKGqvqrOAhqAM0Vk4HpZ0uXfr6rzVHVefX39QBZtjDEDqjXwCI5sUzlCoHAg6Hm0ZSkUddSTqrYAvwMWHXFqBzAeQETCQA3pTu2u4xkNmWPDmqqS3LsR1V5+24wxg0614+L00k/tCNQ4R68sWyoFTxQiUi8itZnXZcAC4M0jLnsCuDHz+irgeU2/Cz4BXC0iURGZBJwEvFLomAc7/+AOWl/5X/gHd5Y6FGNMP81263AlhHeMVR88DXAlxGy3Lqfyr7nmGs4++2w2b95MQ0MDP/jBD/IJFyjOqKcxwI9EJEQ6MT2qqk+KyB3AKlV9AvgB8KCIbAH2kR7phKq+LiKPAm8AKeC2Yo54Gqy8v67Gb/8r3nurCFflv3uVMaZ4YpkhsIdGPXXvq/A0YH/gsaRyClEJ5VT+ww8/PFChdil4olDV14DZPRz/UrfXceCjx7j/q8BXCxbgEKB+Em/3WtAUAIl3n8OJjSDxl+WEyjN9MhLGHT0bCUWylGSMGQwWlY0B4MH2rV19FofmUSypnNJ1frCw1WOHAA08Ot58hFTzG0i0BhEHJzaSoHMPbavvRRMHCI88lcio6ZYojBkCRITF5WO5oOwE1nn7ORB41Dgus926nGsShWSJYghwIhXUnPP/0P76D0ls/z3iVqVnbbpVaKKF2JTLqJxxExIuK3Woxph+iEmIs6KjSh1Gr2ytpyHCiZRTefqthCrHor6HpuKo7xGqHEvl6bdakjDGFIzVKIaQoLMZv3V7eunzcAxNxfG9NoLOZkLlg/9TiTFmaLIaxRDi7V4DBJSddAUjFn6PspMuB4J0R7cxxhSI1SiGkFDVeGrO+SqRkacCUDHtE7ijZ6HktsqkMaa01O/Eb14N3gFwawiNnIuE8mtG3r59OzfccAPvvfceIsKSJUv4zGc+k1eZliiGEHfktKOOHUoaxpihQ1VJNf2a5JalEHioBog44LhEptxMuOHSnJcZD4fDfP3rX2fOnDm0tbUxd+5cFixYwKmn5v5eYYnCGGOKLNX0a5Kb7wO3DnGru9oE1PfSx4HI+MtyKnvMmDGMGZOeh1FVVcW0adPYsWNHXonC+iiMMaaI1O9M1yTcOiR0+HpOEnLBrSO55QHUj+f9rG3btrF27Vrmz5+fVzmWKIwxpoj85tUQeEcliUMk5EKQSF+Xh4MHD3LllVdyzz33UF1dnVdZliiMMaaYvAPoMRYEPEQ1AK8l50ckk0muvPJKrr32Wq644oqcyznEEoUxxhSTm16GJxsRB9zanIpXVW655RamTZvG5z73uZzKOJIlCmOMKaLQyLnguKjf88ZE6nvgRNPX5eDFF1/kwQcf5Pnnn2fWrFnMmjWLp556Kp+QbdSTMcYUk4TKiEy5meTm+9AjOrTV98DbT2TqbUgollP555xzzoBvamaJwhhjiizccCkAyS1L0WTr4fMopt7WdX6wsERhzCCnqgT7X8OpOy3nSVhmcBERIuMvIzx2AX7zmnTHtVubmZmdW02ikCxRGDPIacd2Euu/ROzMbyMV43u/wQwZEiojPPqDpQ6jV8XYM3u8iPxORN4QkddF5KhFR0Tkn0VkXeZro4j4IjIic26biGzInFtV6HiNGWz8PSvRzp34e14qdShmmCpGjSIFfF5V14hIFbBaRJap6huHLlDVrwFfAxCRS4HPquq+bmVcoKp7ixCrMSWngYe/99WurW9TO55GoiNJ7XwaKTshfZGECY06A3F6nrRlzEAqxp7Zu4BdmddtIrIJGAe8cYxbrgEGfndwY4YK3yP59o8IWl5DIrXp/Uei9Wjne3gb7kSTLTi1pxGqOx0sUZgiKOo8ChGZCMwGXj7G+XJgEfCLbocVeFZEVovIkmPct0REVonIqj179gxw1MYUl0QqiZ1xD+EJHwU0M0FLwK0BlPCEjxI74x4kUlnqUE2eUp7HXzf/mXfXreOvm/9Myut5bkV/xONxzjzzTE4//XSmT5/Ol7/85bzLLFpntohUkk4At6tq6zEuuxR48Yhmp3NUdYeIjAaWicibqrqi+02qej9wP8C8efMGdgCxMSUg4XLcaZ8jfmATmtiHqg9BCqkYjzvtczb6aYhTVd5du5bNf1hBkEoRaIAjDk44zNTzzqVx9uyc/42j0SjPP/88lZWVJJNJzjnnHBYvXsxZZ52Vc7xFSRQiEiGdJH6iqo9lufRqjmh2UtUdmT93i8jjwJnAih7uNea4ook9BAe3pcfXh8rB7yBItqKJPUhsdKnDM3l4d+1aXl/2HNHKCtzy9zcq8lMpXl/2HAAT5szJqWwRobIyXdtMJpMkk8m8P1gUY9STAD8ANqnqN7JcVwOcB/yq27GKTAc4IlIBLAQ2FjZiYwYHf+8riCrhiZ+g7NyHCU+8BlFNd3SbISvleWz+wwqilRWEwod/Vg+Fw0QrK9i8YgV+MpnzM3zfZ9asWYwePZoFCxbkvcx4MWoUHwSuBzaIyLrMsX8DGgFU9buZY5cDz6pqe7d7TwAez2TDMPBTVX2mCDEbU3JSMYHoGXcTqjsNAHfKTYRGzrWtb4e4vVu3EaRSh9UkuguFwyQ7OtmzdSsnnnxyTs8IhUKsW7eOlpYWLr/8cjZu3MiMGTNyjrkYo55egN5/s1X1h8APjzj2DnB6QQIzZpAL18086tihpGGGLq+zg6DXZcYVr6Mj72fV1tZywQUX8Mwzz+SVKGz1WGPILJORWjXgi6kZcyS3rByn12XGBbe8PKfy9+zZQ0tLCwCdnZ0sW7aMU045JaeyDrElPIwBCLbht3+WcOWDEJpY6mjMcWzUpIk44TB+KnVUHwWkO7SdSJj6SZNyKn/Xrl3ceOON+L5PEAR87GMf45JLLskrZksUxgBBcgUE2wmSKwhZojAFFHZdpp53bteop+7Jwk+lSLS3M/2iiwhFIjmVf9ppp7F27dqBChewRGGGKVUPTb3YtUyGer8EGY16jxM4Y9IXSRgJfxARm/1sBlbj7NkAbP7DCpIdnagqIoITDjP9oou6zg8WlijMMJUgiH8HTa0GGQk4ICegwS78jn8D3YeE5xKqnAdYojADS0SYMGcO42bMYO+2bXgdHbjl5dRPmpRzTaKQrDPbDEsiVYQqH8CJ3gAEILXpSUlSCyhO9AZClT8kM41n0FBVtq15wzrdjxNh1+XEk0+mcdYsTjz55EGZJMAShRnGRCpwyr6EhCYCcVQ7gTgSmpg+LrmNOimkvX/Zyc++eDfN7+4qdShmGLFEkRH4ncR3v0hH02+I736RwO8sdUimGPQ91N8C2gbEQdtQ/23Q9wb+Uaqsbz6YV23grRfXsq/pr/z5hYHtrDQmm2HfR6GqdDY9SduWpemNzTUAcZCQS9WUmylruMQWYDuOBckXAcWJ3YITvYkgvpQgcT9B8k+EolcM6LO2tyf4j9Vb+ebfnMT4yr5td5nykmx5aT2B7wOw9onfU1U/grW//j21Y0YB4IRCTDn7dMLu4Gy2MEPfsE8UnU1P0vrmfTjuCJxITddx9T1a37wPgPLxg2ujczNwxJlMuPIBJJxegC1UdhtO5GxUB/7Dwcr3WtnZnmDl7ta+J4qEx++//wv+snYTFXU1OCGH6tEjOPDXvTz25fto39/GhNmnMHHONEsUQ5AfT7Fv406SbQkiVVFGzBhLKJb/27Lv+8ybN49x48bx5JNP5l3esE4Ugd9J25alOO4IJHT4yBYJuTjuCNq2PEDZ2AWDcsNzkz8ncvQwRAnPGZDVlDw/4NU9bfiZpqZnmpoZGYvwzPZmTihL/76FRDijvgo31HMrcKyqgpu++yWevfch1j31R8pqKhERymoqOdh8gL/5xMUsvP16ouX2+zmUqCo7n3+Ldx5dS5D03x8eGwkx+WOzGfuhk/Jqybj33nuZNm0ara3H2tGhf4Z1ovCa16C+d1hNojsJuQSpVhLNq4kNgQ3QzeDiBcqP3/orG/YdpNYN4wjUxyK81+lx17q/0OKlmDmiktNHVuKGjl1OtKKMS/71UzS9voWDzS0Evk+Q8hk1YQyX/OunrGl0CNr5/Fu89eAruNVlRKqiXccDz+etB18BYNyFuS0I2NTUxG9+8xv+/d//nW9845gLdvfLsO7MDryWdJ9ENhqkrzOmnyojIe4+ewpXTapHFWrcMCJCjRtGFa6aVM89Z0+hMpIlS2S07m5m99tNxA92kEokiR/sYPc7TbTubi7CT2IGkh9P8c6ja3Gry3CO+ITguCHc6jLe+e91+IlUTuXffvvt/Od//ieOM3Bv78M6UThubXo/4mzESV9nTA7KwyE+O3M84yujJHwlngpI+Mr4yiifnTmesnDvSQLgrZfWoxpwzg0f4bNPfItzrr8MDQK2rHytwD+BGWj7Nu4kSPpHJYlDHDdEkEyxb2P/h0A/+eSTjB49mrlz5+Yb5mGGddOTO3IOEnJR3zuqjwLSHdriuERHDuxfuhle9sSTbGuL44hQFnboTAW0ein2xJOMLuvbrO/Rkxq46b++zIRZ6VVAL/j7jzJ5/kxrdhqCkm2J3odIB0qyNd7vsl988UWeeOIJnnrqKeLxOK2trVx33XU89NBDOUabNrxrFKEyqqbcTODtSw+N7UZ9j8DbT9WUm6wj2+Tl1T2tBMA1U0bz0w+dytUfGE0ArNrT947GxtOndiWJQybMOoXG06cObLCm4CJV0d4TvCNEqvv/vnPnnXfS1NTEtm3beOSRR/jQhz6Ud5KAYV6jAChrSC+/27ZlKUGq9f15FE6E6lP+oeu8MbmaUBnj7rOnMHNEeh/jT04dw9z6KtunbpgaMWMsTiRE4PXc/BR4Pk4kzIgZY0oQXc8KnihEZDzwY9Lbmipwv6ree8Q155PeK3tr5tBjqnpH5twi4F4gBHxfVe8a4PgoH38psbEX4TWvIfBacNxaoiPnWk3CHKUz5bNm70FavBS1bpg5oyp77WeYkUkQ3c3s4ZgZHkKxMJM/Nrtr1FP3ZBF4Pl5rnJOuP4NQNL+35/PPP5/zzz8/z2jTilGjSAGfV9U1kl5hbbWILFPVN4647o+qetjHdxEJAfcBC4Am4FUReaKHe/PmhMpsCKw5JlXlyXebWbp5F14QEATgOOA6DjdPHcMljSOtv8D02dgPnQTAO4+uJdmegEDBEZxwiJOuP6Pr/GBRjD2zdwG7Mq/bRGQTMA7oy5v9mcCWzN7ZiMgjwEf6eK8xA+bJd5u57/UdjIiGqXHf/2/j+QH3vb4DgEsnjCpVeGaIERHGXXgyJ35wMvte30WyNU6kOsaIGWPyrkkUQlEjEpGJwGzg5R5Ony0i64GdwBdU9XXSCWV7t2uagPmFjtOY7jpTPks372JENHzUDGo35DAiGuaBzbtY0DCC2DFmWAOkPI+9W7fhdXbglpUzatJEwq7tdTGchWJh6ueOL3UYvSpaohCRSuAXwO2qeuRwjzXABFU9KCIXA78E+lz3EpElwBKAxsbGgQnYmIw1ew/iBcFhNYnu3JBDazLF6j1tfPDEo2f5qyrvrl3L5j+sIEilCDTAEQcnHGbqeefSOHu2NVuZQa0ow2NFJEI6SfxEVR878ryqtqrqwczrp4CIiIwCdgDd021D5tiR99+vqvNUdV59fX1BfgYzfLV4KYJeJvAHmr6uJ++uXcvry54j5EaIVVdRXlNDrLqKkBvh9WXP8e4A729szEAreKKQ9EelHwCbVLXHhUdE5MTMdYjImZm4moFXgZNEZJKkNy6+Gnii0DEb012tG6a31RAcSV93pJTnsfkPK4hWVhAKH34+FA4Traxg84oV+MnkQIZszIAqRtPTB4HrgQ0isi5z7N+ARgBV/S5wFXCriKSATuBqTU9dTInIp4Hfkh4euzTTd2FM0cwZVYnrOHh+0OMqr54f4DoOc+uP3jZ179ZtBKkUbnlZj2WHwmGSHZ3s2bqVE0/ObRE4M3TlMty6LyZOnEhVVRWhUIhwOMyqVavyKq8Yo55egOxzi1T128C3j3HuKeCpAoRmTJe4+qz19tMaeFQ7LrPdOmKS/g9bFg5x89QxXaOeuicLzw/Yn0jxD9PH9diR7XV2EPSy8KSq4nV0DOwPZAa1Ygy3/t3vfseoUQMzEm/wjcMypohUlWc6d/Fg+1Y89Q8NZ8eVENdXTGJR2RhEhEsaRwKwdPMuWpOprusijsM/TB/Xdf5Iblk5Ti8LT4oIbvng25/bFM5QG25ticIMa8907uL+g1uoc1yqnfd3iPM04P6DWwBYXD4WEeHSCaO4aFzdYU0Fc+ursg6JHTVpIk44jJ9KHdVHAeCnUjiRMPWTJg38D2cGpYEabp2NiLBw4UJEhL//+79nyZIlecVsicIMW3H1ebB9K3WOi3vEp35XHOoclwfbt/KhshOIdmuG6mkI7LGEXZep553L68ueO6pD20+lSLS3M/2iiwhFbBvT4SLf4dZ98cILLzBu3Dh2797NggULOOWUUzj33HNzjnlYrx5rhre13n489Y9KEoe44uBl+i7y0Th7NtMXXITvJYm3ttF5oJV4axu+l2T6RRfROPvo7VjN8Svf4dZ9MW7cOABGjx7N5ZdfziuvvJJzWWA1CjOMtQYeQe/bAnAg8LJf1AsRYcKcOYybMYO927bhdXTglpdTP2mS1SSGoXyGW/dFe3s7QRBQVVVFe3s7zz77LF/60pdyKusQSxRm2Kp2XJzetwWgxhmYZTbCrmtDYE1ew6374r333uPyyy8HIJVK8YlPfIJFixblFbMlCpOVqrJv+3ZGjB9/3C0zMdutw5UQngY9Nj+lj4eY7daVIDpzvMpnuHVfTJ48mfXr1w9UuID1UZhetDfvY/UvHqN9375ShzLgYpkhsPsDD++IuQ6eBuwPPK6vmNTVkW3MQLmkcSS3TR9Hpx+wN+6xu9Njb9yj0w+yDrcuFatRmKzee3sL7fv3s3vL21SOHFy/vANhUVl6F7EH27d29VkcmkexpHJK13ljBlKuw61LxRKFOYyfSrHnnXfQzLCMpvWvEauqZPv69ZTVVAMgjkP95Mk9zgsYakSExeVjuaDsBNZ5+zkQeNRkZmb3pSbhdcZ5++UNdLS0UV5bxQfmz8Qts50RTd/0d7h1qQz9/+lmQAWpFG/98QX2bd+OW16OOA6xqio6W1tZ98Sv8To6GDF+PCMbG4+LRHFITEKcFe37TFhVZfXjy1n+nZ+RSiQJggDHcQhHI1x468eZe/mFx12fjhm+jp//6WZARGIxzr7uWt5Y/jxNGzcSLYull5goixFv72DSmWdy6kUXDvsNd1Y/vpynv/4jKkfWUF77/uiUVMLj6a//CIB5V1yU93PU78RvXg3eAXBrCI2ci4R6XmDQmEKxRHEcUVWS+18jUndaXp9mw9EoMxcvomXnThLtBwmCAA0CKkeMYObiRcP+k7LXGWf5d35G5cgawtHDE2Y46lI5sobl332U0y/+P4jEojk9Q1VJNf2a5JalEHioBog44LhEptxMuOHSYf/vYIpn8PWamJz5HdvZv+4/8Dua8i4r3tZG2949JOMJgpRPMp6gbe9e4m1tAxDp0Pb2yxtIJZJHJYlDwlGXVMLj7Zc35PyMVNOvSW6+D0IxJDYKp2w0EhsFoRjJzfeRavp1zmWbwUO1kyD5PEHiFwTJ51HtHJByW1pauOqqqzjllFOYNm0aL730Ul7lWY3iOJLYsxK/cyeJPSsJV+S3D++et98GhSl/czaTz5rP2ytXsuXFP7Hn7XdonD1rYAIeojpa2gh6WYNBg4D2/Ufu+Ns36nemaxJuHRI6PBlJyEXdOpJbHiA8diESso7zoUhVCbyfo/FvgnooAYID4iKxf8Jxr8qrxviZz3yGRYsW8fOf/xzP8+jIcxl7SxRDmAYeib2vgvoAdOx4Bic6ko4dzxAqOyF9kYSIjjoD6efs4spRozj7umsZMT6dcKaee66tcJpRXluF08saDOI4VNRV51S+37waAg9xe75fQi6abMVvXk149AdzeoYprcD7OUHnXSCjEKeua8Me1QTaeRcAoehHcyr7wIEDrFixgh/+8IcAuK6Lm2efoiWKIUx9j4Nv/xhv/wYctxbEwYnW48ffo2XDXQReC27dTNy60/udKA4liN6ODUcfmD+TcDRCKuH12Px06PgH5s/M7QHegXSfRJZLVAPwWnIr35SUame6JiGjEDm8D0skijIKjX8LdS9FpP81xq1bt1JfX89NN93E+vXrmTt3Lvfeey8VFRU5x2x9FEOYE6lkxBl3UzHhKlDFidQgIjiRGlClYsJVjDjjHpxIZalDPa64ZTEuvPXjHGw+QCpx+IKBqYTHwX0HuPD/+ljOHdm4NemO6yxEHHBrcyvflJSmXgL1jkoSh4hEQRPp63KQSqVYs2YNt956K2vXrqWiooK77rorn5ALnyhEZLyI/E5E3hCR10XkMz1cc62IvCYiG0TkTyJyerdz2zLH14lIfhu/HoeccDnVp36WcMV41E+gfhz1E4QrxlN96mdxwjaUshDmXn4hiz9/I15ngtbd+zjw17207t6H15lg8eduZO7lF+ZcdmjkXHBc1O951Vr1PXCi6evM0BPsR+mlj4sAgtyWzWloaKChoYH58+cDcNVVV7FmzZqcyjqkz01PIrIA+Bhwn6quE5Elqnp/H25NAZ9X1TUiUgWsFpFlqvpGt2u2Auep6n4RWQzcD8zvdv4CVd3b11iHmyCxh9TBbSAOhMvQVCepZCtBYg+h2OhSh3dcEhHmXXERpy0+h3de2Uj7/lYq6qr5wPyZudckDpUdKiMy5WaSm+9Dj+jQVt8Dbz+RqbdZR/ZQ5dSlO66zEBxwRuRU/Iknnsj48ePZvHkzU6dOZfny5Zx66qk5lXVIf/oobgZuBf6HiIwAZvXlJlXdBezKvG4TkU3AOOCNbtf8qdstK4GGfsQ17KU7tAMqJl9LxaSP0b71Z7S//RCJvasob7i41OEd19yyGKecN2/Ayw03XApAcstSNNl6+DyKqbd1nTdDj4TPBnFRTfTY/HTouITPzvkZ3/rWt7j22mvxPI/JkyfzwAMP5BNyvxJFm6q2AF8QkbuAM/r7MBGZCMwGXs5y2S3A092+V+BZEVHgv3qqxYjIEmAJQGNjY3/DGvJCFRMYcebduHXpztOqKZ8kOnIumrU71AxmIkJk/GWExy7Ab16T7rh2azMzs60mMZSJlCGxf0I770I5vENbNQHajJR9MaeO7ENmzZrFqlUD11Lfa6IQkbmquhr4zaFjqvovIvKP/XmQiFQCvwBuV9UeB5iLyAWkE8U53Q6fo6o7RGQ0sExE3lTVFd3vyySP+wHmzZvXy55lx59o3Yyjjh1KGmZok1CZDYE9DjnuVQDp0U9BS9c8ChEXKfti1/nBoi81ihtF5F+Brx86ICLfUNXP9fUhIhIhnSR+oqqPHeOa04DvA4tVtfnQcVXdkflzt4g8DpwJrOipDGOMGQpEhFD0o6h7CZpame64dkYg4bPzqkkUSl8SxW7gMuAXItIGuECfx21JenrhD4BNqvqNY1zTCDwGXK+qf+52vAJwMn0bFcBC4I6+PtsYYwYzkTIkckGpw+hVXxLFdcBUVU2IyFjgTmBtP57xQeB6YIOIrMsc+zegEUBVvwt8CRgJ/O/MtPWUqs4DTgAezxwLAz9V1Wf68WxjjDF56kui2A5MAt5U1Z2km6I2Aff05QGq+gJk71VV1U8Bn+rh+DvA6UffYYwxplj6kig+Q7rZaQ3pmsQ4oL2gURlj+i2uAa8FcVo1oFocTnNixHqZ4W1MX/SaKFT1DRGZA1xEeu7EX4GPFDguY0wfqSrL/HYeTrWQBAJVHBEiwDXhWhaEKmzvikEq8DvxmtcQeC04bi3uyDk4eW5MtXnzZj7+8Y93ff/OO+9wxx13cPvtt+dcZp/mUahqgvTw2N/0dq0xw42q0vLme9SeckJJ3pCX+e08kNxPLSGqRboaej1VHkjuB2Bh2Nb7GkxUlc6mJ2nbsjQ9214DEAcJuVRNuZmyhkty/l2aOnUq69atA8D3fcaNG8fll1+eV7xWLzUmTx27Wtl4zx/o/Gtu+0/kI64BD6daqCWEe8QbiytCLSEeSR0godnXFjLF1dn0JK1v3oc4ZYRi9YTKTiAUq0ecMlrfvI/OpicH5DnLly/nAx/4ABMmTMirHEsUxuSpeW0Tne+1sXdt/jsL9tdrQZwkHJUkDnFF8FBeCxLFDcwcU+B30rZlKY47oseNqRx3BG1bHkD9eN7PeuSRR7jmmmvyLsf2ozCmn4KkT/NrO1E//Sl914otuHVl7PrD28RGpZt4JOQw8rSxOJFQQWNp1YBANeu4wkCVA5nNrUzpec1rUN9LbwfQAwm5BKlWEs2rieUxK9/zPJ544gnuvPPOnMs4xBKFMf3kez7bHltPy5vvEamOIY4QHVFOfO9B3vjOCyRbE9SeMpraU04oeKKoFgenl7ZsR4QaKWwcpu8CryXdJ5GNBunr8vD0008zZ84cTjjhhLzKAWt6MqbfIhUus//Hhxm/+FRQiFRG04v4VUZBYfziacz+nx8mUpHf9pN9cZoTI0K647onniouwmlOfkufm4FzaDfKrMRJX5eHhx9+eECancAShTE5CZdFmHrLWZSPqSbwfPxEisDzKR9TzdRbziIcixQljpg4XBOupQX/qGThqdKCz9XhGqI2n2LQcEfOSe97nmVjKnFconlsTNXe3s6yZcu44oorci6jO/vtMSZHiX0dtDe1kOrwCDyfVIdHe9MBEvs6ihrHglAFN0XqiEtAMz57NEUzPnEJuClSx4JQ7nslm4HnhMqomnIzgbfvqGShvkfg7adqyk15LSdfUVFBc3MzNTU994P0l/VRGJOj5vU7QaHxsplM+D+n85cnN/KXX25g32s7GXvBSUWLQ0RYGK7k3FA5G4IEB9SnRkKc5kStJjFIlTVcAkDblqUEqdb351E4EapP+Yeu84OFJQpjclQxrprZ/3MhtVPTnYWTr5rFiJljBvQZqp1o6iUI9qe30AyfjUjPM3dj4nBGnrN6TXGICOXjLyU29qLDZmZHB+nGVJYojMnRoQTR27FcqCqB9/P0xjbqdW1sg7hI7J9w3KtsWY7jgBMqy2sIbLFYojBmEAq8nxN03gUyCnHquqZJqCbQzrsACEU/WroAzbBiDZjGDDKqnemahBy+nzKQ/l5GofFvoZr/zF1j+sIShTGDjKZeAvWOShKHiERBE+nrjCkCSxTGDDbBfpTsM3eVIL3PshnSNBUnsetl4tuWkdj1MprKv5Z49913M336dGbMmME111xDPJ5/mQVPFCIyXkR+JyJviMjrIvKZHq4REfmmiGwRkdcy+18cOnejiLyV+bqx0PEaU3JOXbrjOgvBAWdEkQIyA01V6dz6W/Y9+3e0rb6bgxu+R9vqu9n37N/RufW36DFm2vdmx44dfPOb32TVqlVs3LgR3/d55JFH8o63GJ3ZKeDzqrpGRKqA1SKyTFXf6HbNYuCkzNd84DvAfBEZAXwZmAdo5t4nVHV/EeI2piQkfDaIi2qix+anQ8clfHYJojMDIb7tWdo3fB8nWovjVncdV9+jfcP3ASib9OGcyk6lUnR2dhKJROjo6GDs2LF5x1vwGoWq7lLVNZnXbcAm0tupdvcR4MeathKoFZExwIeBZaq6L5MclgGLCh2zMaUkUobE/gl0L+k9w96nmgBtRmL/iMjgG29veqepOB2bHsKJ1va8zHi0lo5NP0FT/V8afty4cXzhC1+gsbGRMWPGUFNTw8KFC/OOuah9FCIyEZgNvHzEqXHA9m7fN2WOHeu4Mcc1x70Kp+xfEDogeA8NdkHwHkIHTtkXcdyrSh2iyZG3Zz0aJI9KEodIyEUDD2/P+n6XvX//fn71q1+xdetWdu7cSXt7Ow899FC+IRdvHoWIVAK/AG5X1QHdCkxElgBLABobGweyaGNKQkQIRT+KupegqZXpjmtnRGZmttUkhjJNtPZhmXFFEwf6XfZzzz3HpEmTqK+vB+CKK67gT3/6E9ddd10uoXYpSo1CRCKkk8RPVPWxHi7ZAYzv9n1D5tixjh9GVe9X1XmqOu/QX5AxxwORMpzIBTjRK3EiF1iSOA5ItLoPy4wLEu3/gn6NjY2sXLmSjo4OVJXly5czbdq0HCN9XzFGPQnwA2CTqn7jGJc9AdyQGf10FnBAVXcBvwUWikidiNQBCzPHjDFmSHLrT0ecSK/LjLv1p/e77Pnz53PVVVcxZ84cZs6cSRAELFmyJN+Qi9L09EHgemCDiKzLHPs3oBFAVb8LPAVcDGwBOoCbMuf2icj/Dbyaue8OVbXB48aYIUvCMcqnXdc16ql7X4X6HkGihYqZn0LCuW029ZWvfIWvfOUrAxUuUIREoaovkHVHX9D0oOHbjnFuKbC0AKEZY0xJxCamRyJ1bHqIINkGqunmJidCxcxPdZ0fLGxRQGOMKTIRoWzSh4mNPw9vz2to4gASrUk3S+VYkygkSxTGGFMiEo4RHXNmqcPola31ZIwxJitLFMYYY7KyRGGMMSYrSxTGGFMicQ14xe/gudRBXvE7iPc2Y7sP7r33XmbMmMH06dO555578g8S68w2xpiiU1WW+e08nGohCQSqOCJEgGvCtSwIVeS0J/rGjRv53ve+xyuvvILruixatIhLLrmEKVOm5BWv1SiMMabIlvntPJDcT0wdRhKiXsKMJERMHR5I7meZ355TuZs2bWL+/PmUl5cTDoc577zzeOyxnlZN6h9LFMYYU0RxDXg41UItIdwjag2uCLWEeCR1gEQOzVAzZszgj3/8I83NzXR0dPDUU0+xffv23m/shTU9GWNMEb0WxEkC1cdoWnJFaCPgtSDBGaGyfpU9bdo0vvjFL7Jw4UIqKiqYNWsWoVAo75itRmGMMUXUqgFBL1udBqocUD+n8m+55RZWr17NihUrqKur4+STT86pnO6sRmGMMUVULQ5OLx3Vjgg1kltNYPfu3YwePZp3332Xxx57jJUrV+ZUTneWKIwxpohOc2JEAE/1qD4Kuh0/zcltzacrr7yS5uZmIpEI9913H7W1tfkFjCUKY4wpqpg4XBOu5YHkfmr18A5tT5UWfG4K1xHtbXOjY/jjH/84UKF2sURhjDFFtiBUAcDDqRba6DaPQuCmcF3X+cHCEoUxxhSZiLAwXMm5oXI2BAkOqE+NhDjNieZckygkSxTGGFMiMXH6PQS2FAZf6jLGmCFMexn6Wmq5xFfwRCEiS0Vkt4hsPMb5fxaRdZmvjSLii8iIzLltIrIhc25VoWM1xph8xGIxmpubB22yUFWam5uJxWL9uq8YTU8/BL4N/Link6r6NeBrACJyKfBZVd3X7ZILVHVvoYM0xph8NTQ00NTUxJ49e0odyjHFYjEaGhr6dU/BE4WqrhCRiX28/Brg4QKGY4wxBROJRJg0aVKpwxhwg6aPQkTKgUXAL7odVuBZEVktIkuy3LtERFaJyKrBnMmNMccXVeV1Pz5om5oGyqBJFMClwItHNDudo6pzgMXAbSJybk83qur9qjpPVefV19cXI1ZjjGGnpvj/ks3s0lSpQymowZQoruaIZidV3ZH5czfwOHBmCeIyxpgerfE7+WuQZLXfWepQCmpQzKMQkRrgPOC6bscqAEdV2zKvFwJ3lChEY4whqcq6II5Puqnpeb+dERLieb+deif9dhpCmOXEiOSwQ91gVfBEISIPA+cDo0SkCfgyEAFQ1e9mLrsceFZVu2/rdALweGY7wDDwU1V9ptDxGmPMsXgoj6YOsClIUEMIAUYSYo/6fNNrppWAaU6UU90oEY6fRCHHWyfMvHnzdNUqm3JhjCmMTg34cbKFP/jt1BIiIkIys5jfeaEKbojUUjYIl+HojYisVtV5PZ0bej+NMcaUUJk4LInUMdaJ4KHENcBDGetEWBKpG5JJojeDoo/CGGOGkmZ8tgdJHNLrNcU1oC0IaMZn1HH4tnr8pT5jjCmwdX6cAOXycDXfiY7hb8PVBCjr/HipQyuI4y/1GWNMgTVImDuiJzAtswvdxyM1nBaKIcdZn+8hliiMMaafTgkdvajetBy3Lh0KrOnJGGNMVpYojDHGZGWJwhhjTFaWKIwxxmRlicIYY0xWliiMMcZkZYnCGGNMVpYojDHGZGWJwhhjTFaWKIwxxmRlicIYY0xWliiMMcZkVfBEISJLRWS3iGw8xvnzReSAiKzLfH2p27lFIrJZRLaIyL8UOlZjjDFHK0aN4ofAol6u+aOqzsp83QEgIiHgPmAxcCpwjYicWtBIjTHGHKXgiUJVVwD7crj1TGCLqr6jqh7wCPCRAQ3OGGNMrwZLH8XZIrJeRJ4WkemZY+OA7d2uacocM8YYU0SDYeOiNcAEVT0oIhcDvwRO6k8BIrIEWALQ2Ng44AEaY8xwVvIahaq2qurBzOungIiIjAJ2AOO7XdqQOdZTGfer6jxVnVdfX1/wmI0xZjgpeaIQkRNFRDKvzyQdUzPwKnCSiEwSERe4GniidJEaY8zwVPCmJxF5GDgfGCUiTcCXgQiAqn4XuAq4VURSQCdwtaoqkBKRTwO/BULAUlV9vdDxGmOMOZyk35OPH/PmzdNVq1aVOgxjjBlSRGS1qs7r6VzJm56MMcYMbpYojDHGZGWJwhhjTFaWKIwxxmRlicIYY0xWliiMMcZkZYnCGGNMVpYojDHGZGWJwhhjTFaWKIwxxmQ1GJYZN8YYkwc/nmLfxp0k2xJEqqKMmDGWUGzg3t4tURhjzBClqux8/i3eeXQtQdJHVRERnEiIyR+bzdgPnURmce68WKIwxpghaufzb/HWg6/gVpcRqYp2HQ88n7cefAWAcReenPdzrI/CGGOGID+e4p1H1+JWl+G4ocPOOW4It7qMd/57HX4ilfezLFEYY8wQtG/jToKkf1SSOMRxQwTJFPs27sr7WZYojDFmCEq2Jeh1P6FASbbG836WJQpjjBmCIlXR3juqHSFSHcv7WZYojDFmCBoxYyxOJETg+T2eDzwfJxJmxIwxeT+r4IlCRJaKyG4R2XiM89eKyGsiskFE/iQip3c7ty1zfJ2I2P6mxhiTEYqFmfyx2XitnUcli8Dz8VrjTP7oLELR/Ae3FmN47A+BbwM/Psb5rcB5qrpfRBYD9wPzu52/QFX3FjZEY4wZesZ+6CQA3nl0Lcn2BAQKjuCEQ5x0/Rld5/NV8EShqitEZGKW83/q9u1KoKHQMRljzPFARBh34cmc+MHJ7Ht9F8nWOJHqGCNmjBmQmsQhg23C3S3A092+V+BZEVHgv1T1/p5uEpElwBKAxsbGggdpjDGDSSgWpn7u+IKVP2gShYhcQDpRnNPt8DmqukNERgPLRORNVV1x5L2ZBHI/wLx583oZL2aMMaY/BsWoJxE5Dfg+8BFVbT50XFV3ZP7cDTwOnFmaCI0xZvgqeaIQkUbgMeB6Vf1zt+MVIlJ16DWwEOhx5JQxxpjCkV5n9uX7AJGHgfOBUcB7wJeBCICqfldEvg9cCfwlc0tKVeeJyGTStQhIN5H9VFW/2ofn7elWVjGNAobq6CyLvTQs9tKw2Hs2QVXrezpR8EQxXIjIKlWdV+o4cmGxl4bFXhoWe/+VvOnJGGPM4GaJwhhjTFaWKAZOj3M8hgiLvTQs9tKw2PvJ+iiMMcZkZTUKY4wxWVmiMMYYk5Ulin4SkUUisllEtojIvxzjmo+JyBsi8rqI/LTYMR5Lb7GLyN2ZJd3XicifRaSlBGH2qA+xN4rI70RkbWbZ+otLEWdP+hD7BBFZnon79yIyKBbG7MMWASIi38z8XK+JyJxix3gsfYj9FBF5SUQSIvKFYseXTT5bMxSMqtpXH7+AEPA2MBlwgfXAqUdccxKwFqjLfD+61HH3NfYjrv9HYGmp4+7H3/v9wK2Z16cC20oddz9i/2/gxszrDwEPljruTCznAnOAjcc4fzHpRTwFOAt4udQx9yP20cAZwFeBL5Q63n7G/jfd3l8WF+Pv3WoU/XMmsEVV31FVD3gE+MgR1/wdcJ+q7oeudaoGg77E3t01wMNFiax3fYldgerM6xpgZxHjy6YvsZ8KPJ95/bsezpeEphfg3Jflko8AP9a0lUCtiOS/ndoA6C12Vd2tqq8CyeJF1Td9iP1Ph95fKNLWDJYo+mccsL3b902ZY92dDJwsIi+KyEoRWVS06LLrS+xAuikEmMT7b16l1pfY/wO4TkSagKdI14gGg77Evh64IvP6cqBKREYWIbZ89fl3yhTMkVszFIQlioEXJt38dD7pT+XfE5HaUgaUg6uBn6tqz5vxDk7XAD9U1QbSTSIPishQ+f3+AnCeiKwFzgN2AEPp796UQLetGb5Y6GcNmv0ohogdQPfdQRoyx7prIt1mmAS2isifSSeOV4sT4jH1JfZDrgZuK3hEfdeX2G8BFgGo6ksiEiO9gFqpm/56jV1Vd5KpUYhIJXClqrYUK8A89Od3ygygblszLNZuWzMUylD5xDVYvAqcJCKTRMQl/Yb6xBHX/JJ0bQIRGUW6KeqdIsZ4LH2JHRE5BagDXipyfNn0JfZ3gQsBRGQaEAP2FDXKnvUau4iM6lb7+VdgaZFjzNUTwA2Z0U9nAQdUdVepgzreHWtrhkKyGkU/qGpKRD4N/Jb0aJalqvq6iNwBrFLVJzLnForIG6SbD/65GBm/N32MHdJvZI9oZkjFYNDH2D9Pupnvs6Q7tj85GH6GPsZ+PnCnpLf8XcEgqc113yIg0/dz2BYBpPuCLga2AB3ATaWJ9Gi9xS4iJwKrSA+ACETkdtKj0VpLE/H7+vD3/iVgJPC/RQQyWzMUNKZB8H/JGGPMIGZNT8YYY7KyRGGMMSYrSxTGGGOyskRhjDEmK0sUxhhjsrJEYYwxJiubR2FMAYnIdOBeoBF4kPSqpT/OLEhnzJBg8yiMKZDMMiJrgI+Snp3/JrBaVa/IeqMxg4w1PRlTOBcBa1X1dVXtJL0fxddFZLKI/EBEfl7i+IzpE0sUxhTOLNKbWCEiY4GDqvpiZm+KW0oamTH9YInCmMLxeH9/hjtJ1yiMGXIsURhTOD8FzhWRzaQ3J3pJRO4pbUjG9J91ZhtTZJnd674KLAC+r6p3ljgkY7KyRGGMMSYra3oyxhiTlSUKY4wxWVmiMMYYk5UlCmOMMVlZojDGGJOVJQpjjDFZWaIwxhiTlSUKY4wxWVmiMMYYk9X/D9kd9qqJNVc9AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative error:  0.16430525 0.10185999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_alpha, data_alpha_ = [], []\n",
    "\n",
    "for idx in range(10):\n",
    "#     idx=5  # index of sample to test: 0-10\n",
    "    test_s = np.array(test_data[idx]['sa'])[:, :-1]\n",
    "    test_a = np.array(test_data[idx]['sa'])[:, -1:]\n",
    "    test_param = np.array(test_data[idx]['params'])\n",
    "    test_s_ = np.array(test_data[idx]['s_'])\n",
    "    # print(test_s.shape, test_a.shape, test_param.shape, test_s_.shape)\n",
    "\n",
    "    # load model\n",
    "    updater = DynamicsParamsOptimizer(state_dim, action_dim, param_dim, latent_dim, switch_dim, model_save_path)\n",
    "    updater.model.load_state_dict(torch.load(model_save_path+'model', map_location=device))\n",
    "\n",
    "    num_test_data = 200\n",
    "    alpha = updater.model.get_latent_code(test_s[:num_test_data], test_a[:num_test_data], test_s_[:num_test_data])\n",
    "    average_alpha = alpha.mean(dim=0).detach().cpu().numpy()\n",
    "\n",
    "    # compare with encoded value\n",
    "    alpha_ = (torch.Tensor([test_param]).to(device)@updater.model.E)[0].detach().cpu().numpy()\n",
    "    print(average_alpha, alpha_)\n",
    "    data_alpha.append(average_alpha)\n",
    "    data_alpha_.append(alpha_)\n",
    "\n",
    "display_points(data_alpha, data_alpha_)\n",
    "\n",
    "errs = []\n",
    "for i, (pred, true) in enumerate(zip(data_alpha, data_alpha_)):\n",
    "    errs.append(np.linalg.norm(pred-true, 2)/np.linalg.norm(true, 2))\n",
    "print('relative error: ', np.mean(errs), np.std(errs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2, 11]) torch.Size([20, 11, 2]) torch.Size([20, 2])\n",
      "tensor([[0.9233, 2.4405],\n",
      "        [0.9887, 2.2670],\n",
      "        [0.9265, 2.4414],\n",
      "        [0.9111, 2.4962],\n",
      "        [0.9200, 2.4609],\n",
      "        [0.9278, 2.4210],\n",
      "        [0.9266, 2.4084],\n",
      "        [0.9680, 2.3002],\n",
      "        [1.0700, 2.0149],\n",
      "        [1.0089, 2.2888],\n",
      "        [0.8684, 2.5229],\n",
      "        [0.9369, 2.2211],\n",
      "        [0.9002, 2.3494],\n",
      "        [1.0794, 2.3070],\n",
      "        [1.2722, 1.7704],\n",
      "        [0.8855, 2.6497],\n",
      "        [0.8225, 2.5316],\n",
      "        [0.8823, 2.4986],\n",
      "        [0.7953, 2.7264],\n",
      "        [0.8401, 2.4558]], grad_fn=<ViewBackward0>) tensor([[0.9298, 2.5999],\n",
      "        [0.9298, 2.5999],\n",
      "        [0.9298, 2.5999],\n",
      "        [0.9298, 2.5999],\n",
      "        [0.9298, 2.5999],\n",
      "        [0.9298, 2.5999],\n",
      "        [0.9298, 2.5999],\n",
      "        [0.9298, 2.5999],\n",
      "        [0.9298, 2.5999],\n",
      "        [0.9298, 2.5999],\n",
      "        [0.9298, 2.5999],\n",
      "        [0.9298, 2.5999],\n",
      "        [0.9298, 2.5999],\n",
      "        [0.9298, 2.5999],\n",
      "        [0.9298, 2.5999],\n",
      "        [0.9298, 2.5999],\n",
      "        [0.9298, 2.5999],\n",
      "        [0.9298, 2.5999],\n",
      "        [0.9298, 2.5999],\n",
      "        [0.9298, 2.5999]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# test on train data\n",
    "test_size = 20\n",
    "test_s = data_s[:test_size]\n",
    "test_a = data_a[:test_size]\n",
    "test_param = data_param[:test_size]\n",
    "test_s_ = data_s_[:test_size]\n",
    "\n",
    "alpha = updater.model.get_latent_code(test_s, test_a, test_s_)\n",
    "\n",
    "# compare with encoded value\n",
    "alpha_ = torch.Tensor(test_param)@updater.model.E\n",
    "print(alpha, alpha_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28c6861e59928cb790236f7047915368f37afc12f670e78fd0101a6f825a02b1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('x': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
