sim_device: 'cuda:0'
graphics_device_id: 0
headless: False

task:
  # used to create the object
  name: FrankaCabinet

  physics_engine: 'physx'

  # if given, will override the device setting in gym. 
  env:
    numEnvs: 4
    envSpacing: 1.5
    episodeLength: 500
    enableDebugVis: False

    clipObservations: 5.0
    clipActions: 1.0

    startPositionNoise: 0.0
    startRotationNoise: 0.0

    numProps: 16
    aggregateMode: 3

    actionScale: 7.5
    dofVelocityScale: 0.1
    distRewardScale: 2.0
    rotRewardScale: 0.5
    aroundHandleRewardScale: 0.25
    openRewardScale: 7.5
    fingerDistRewardScale: 5.0
    actionPenaltyScale: 0.01

    asset:
      assetRoot: "../../assets"
      assetFileNameFranka: "urdf/franka_description/robots/franka_panda.urdf"
      assetFileNameCabinet: "urdf/sektion_cabinet_model/urdf/sektion_cabinet_2.urdf"

    # set to True if you use camera sensors in the environment
    enableCameraSensors: False

  sim:
    dt: 0.0166 # 1/60
    substeps: 1
    up_axis: "z"
    use_gpu_pipeline: True
    gravity: [0.0, 0.0, -9.81]
    physx:
      num_threads: 4
      solver_type: 1
      use_gpu: True
      num_position_iterations: 12
      num_velocity_iterations: 1
      contact_offset: 0.005
      rest_offset: 0.0
      bounce_threshold_velocity: 0.2
      max_depenetration_velocity: 1000.0
      default_buffer_size_multiplier: 5.0
      max_gpu_contact_pairs: 1048576 # 1024*1024
      num_subscenes: 4
      contact_collection: 0 # 0: CC_NEVER (don't collect contact info), 1: CC_LAST_SUBSTEP (collect only contacts on last substep), 2: CC_ALL_SUBSTEPS (default - all contacts)

  task:
    randomize: False
train:
  params:
    seed: 42
    algo:
      name: a2c_continuous

    model:
      name: continuous_a2c_logstd

    network:
      name: actor_critic
      separate: False

      space:
        continuous:
          mu_activation: None
          sigma_activation: None
          mu_init:
            name: default
          sigma_init:
            name: const_initializer
            val: 0
          fixed_sigma: True
      mlp:
        units: [256, 128, 64]
        activation: elu
        d2rl: False

        initializer:
          name: default
        regularizer:
          name: None

    load_checkpoint: False

    config:
      name: FrankaCabinet
      full_experiment_name: FrankaCabinet
      env_name: rlgpu
      ppo: True
      mixed_precision: False
      normalize_input: True
      normalize_value: True
      num_actors: 4096
      reward_shaper:
        scale_value: 0.01
      normalize_advantage: True
      gamma: 0.99
      tau: 0.95
      learning_rate: 5e-4
      lr_schedule: adaptive
      kl_threshold: 0.008
      score_to_win: 10000
      max_epochs: 1500
      save_best_after: 200
      save_frequency: 100
      print_stats: True
      grad_norm: 1.0
      entropy_coef: 0.0
      truncate_grads: True
      e_clip: 0.2
      horizon_length: 16
      minibatch_size: 8192
      mini_epochs: 8
      critic_coef: 4
      clip_value: True
      seq_len: 4
      bounds_loss_coef: 0.0001
